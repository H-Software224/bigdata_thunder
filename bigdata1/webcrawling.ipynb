{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 뉴스 크롤링하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step1. 특정표본 이용하여 추출해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "url = 'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid=008&date=20220827'\n",
    "response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "naver_news_data = soup.select('div.list_body.newsflash_body>ul>li>dl>dt>a')\n",
    "list1=[]\n",
    "for i in naver_news_data:\n",
    "    if i.select('img') == []:\n",
    "    else:\n",
    "        continue\n",
    "print(len(list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid=008&date=20220827'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid=008&date=20220827&page=1000'\n",
    "response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "last_page = soup.select('div.paging>strong')[0].text\n",
    "last_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_news_contents_data = soup.select('div.list_body.newsflash_body>ul>li>dl>dd>span.lede')\n",
    "naver_news_contents_data\n",
    "len(naver_news_contents_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = []\n",
    "naver_news_url_data = soup.select('div.list_body.newsflash_body>ul>li>dl>dt>a')\n",
    "for i in naver_news_url_data:\n",
    "    if i['href'] in list:\n",
    "        continue\n",
    "    else:\n",
    "        list.append(i['href'])\n",
    "len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n",
      "머니투데이\n"
     ]
    }
   ],
   "source": [
    "list4 =[]\n",
    "naver_news_id_data = soup.select('div.list_body.newsflash_body>ul>li>dl>dd>span.writing')\n",
    "for i in naver_news_id_data:\n",
    "    print(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "oid = ''\n",
    "def naver_news_title(list1, oid):\n",
    "    for date in range(20220701, 20220832):\n",
    "        url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid={oid}&date={date}&page=1000'\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        last_page = int(soup.select('div.paging>strong')[0].text)\n",
    "        for page in range(1, last_page+1):\n",
    "            url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid={oid}&date={date}&page={page}'\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "            naver_news_data = soup.select('div.list_body.newsflash_body>ul>li>dl>dt>a')\n",
    "            for i in naver_news_data:\n",
    "                if i.select('img') == []:\n",
    "                    list1.append(i.text.strip())\n",
    "                else:\n",
    "                    continue\n",
    "    return list1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2= []\n",
    "oid= ''\n",
    "def naver_news_content(list2, oid):\n",
    "    for date in range(20220701, 20220832):\n",
    "        url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid={oid}&date={date}&page=1000'\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        last_page = int(soup.select('div.paging>strong')[0].text)\n",
    "        for page in rnage(1, last_page+1):\n",
    "            url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid={oid}&date={date}'\n",
    "            response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            naver_news_contents_data=soup.select('div.list_body.newsfalsh_body>ul>li>dl>dd>span.lede')\n",
    "            for s in naver_news_contents_data:\n",
    "                list2.append(s.text.strip())\n",
    "    return list2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 =[]\n",
    "oid=''\n",
    "def naver_news_url(list3, oid):\n",
    "    for date in range(20220701, 20220832):\n",
    "        url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid={oid}&date={date}&page=1000'\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        last_page = int(soup.select('div.paging>strong')[0].text)\n",
    "        for page in range(1, last_page+1):\n",
    "            url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid={oid}&date={date}'\n",
    "            response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "            soup=BeautifulSoup(response.text, 'html.parser')\n",
    "            naver_news_image_data =soup.select('div.list_body_newsfalsh_body>ul>li>dl>dt>a')\n",
    "            for i in naver_news_image_data:\n",
    "                if i['href'] in list3:\n",
    "                    continue\n",
    "                else:\n",
    "                    list3.append(i['href'])\n",
    "\n",
    "    return list3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list4 = []\n",
    "oid=''\n",
    "def naver_news_id(list4, oid):\n",
    "    for date in range(20220701, 20220832):\n",
    "        url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid={oid}&date={date}&page=1000'\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        last_page = int(soup.select('div.paging>strong')[0].text)\n",
    "        for page in range(1, last_page+1):\n",
    "            url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid={oid}&date={date}'\n",
    "            response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "            soup=BeautifulSoup(response.text, 'html.parser')\n",
    "            naver_news_id_data =soup.select('div.list_body_newsfalsh_body>ul>li>dl>dd>span.writing')\n",
    "            for id in naver_news_id_data:\n",
    "                list4.append(id.text)\n",
    "    return list4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "naver_news_url([],'008')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube API 이용하여 크롤링하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정으로 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from oauth2client.tools import argparser\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DEVELOPER_KEY='AIzaSyDitP67cnauWgzSvRqh0dbV9NAYMK6n5I4'\n",
    "YOUTUBE_API_SERVICE_NAME='youtube'\n",
    "YOUTUBE_API_VERSION='v3'\n",
    "\n",
    "youtube = build(\n",
    "  YOUTUBE_API_SERVICE_NAME,\n",
    "  YOUTUBE_API_VERSION,\n",
    "  developerKey=DEVELOPER_KEY\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = (\n",
    "#     youtube\n",
    "#     .commentThreads()\n",
    "#     .list(\n",
    "#       part='snippet,replies', \n",
    "#       videoId='627HBcT1jWY', \n",
    "#       maxResults=100\n",
    "#       )\n",
    "#     .execute()\n",
    "#     )\n",
    "# response.get('items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while response = (\n",
    "#     youtube\n",
    "#     .commentThreads()\n",
    "#     .list(\n",
    "#       part='snippet,replies', \n",
    "#       videoId='eacvvczvPLo', \n",
    "#       maxResults=100\n",
    "#       )\n",
    "#     .execute()\n",
    "#     )\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def youtube_comments(list5=[], videoId=''):\n",
    "    while \n",
    "    response=(\n",
    "        youtube\n",
    "        .commentThreads()\n",
    "        .list(\n",
    "        part='snippet,replies', \n",
    "        videoId='', \n",
    "        maxResults=100\n",
    "        )\n",
    "    .execute()\n",
    "    )\n",
    "    return [response.get('items')[i].get('snippet').get('topLevelComment').get('snippet').get('textOriginal') for i in range(len(response.get('items')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = (\n",
    "    youtube\n",
    "    .commentThreads()\n",
    "    .list(\n",
    "      part='snippet,replies', \n",
    "      videoId='627HBcT1jWY', \n",
    "      maxResults=100\n",
    "      )\n",
    "    .execute()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 정보 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import xmltodict\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '03880acf9b9a1701f822dbbe25c4340eaaddfe57'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dart_information_url = f'https://opendart.fss.or.kr/api/list.json?crtfc_key={api_key}&bgn_de=20200117&end_de=20200117&corp_cls=Y&page_no=1&page_count=10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dart_information_source = requests.get(dart_information_url)\n",
    "# eval(dart_information_source.text).get('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('CORPCODE.xml')\n",
    "time.sleep(2)\n",
    "xml_data = ET.dump(tree)\n",
    "xml_data\n",
    "# dict_data = xmltodict.parse('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in tree.getroot().iter('list'):\n",
    "#     print(list(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
