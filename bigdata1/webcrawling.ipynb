{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 뉴스 크롤링하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step1. 특정표본 이용하여 추출해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list3=[]\n",
    "# for page in range(1, 7):\n",
    "#     url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid=008&date=20220701&page={page}'\n",
    "#     response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "#     soup=BeautifulSoup(response.text, 'html.parser')\n",
    "#     naver_news_image_data =soup.select('ul>li>dl>dt>a')\n",
    "#     list3.append(naver_news_image_data[0]['href'])\n",
    "# print(len(list3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list3=[]\n",
    "# for page in range(1, 7):\n",
    "#     url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid=008&date=20220701&page={page}'\n",
    "#     response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "#     soup=BeautifulSoup(response.text, 'html.parser')\n",
    "#     naver_news_image_data =soup.select('ul>li>dl>dt>a')\n",
    "#     list3.append(naver_news_image_data[0]['href'])\n",
    "# print(len(list3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list3=[]\n",
    "# for page in range(1, 7):\n",
    "#     url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid=008&date=20220701&page={page}'\n",
    "#     response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "#     soup=BeautifulSoup(response.text, 'html.parser')\n",
    "#     naver_news_image_data =soup.select('ul>li>dl>dt>a')\n",
    "#     list3.append(naver_news_image_data[0]['href'])\n",
    "# print(len(list3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list = []\n",
    "# naver_news_url_data = soup.select('ul>li>dl>dt>a')\n",
    "# for i in naver_news_url_data:\n",
    "#     if i['href'] in list:\n",
    "#         continue\n",
    "#     else:\n",
    "#         list.append(i['href'])\n",
    "# len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid=008&date=20220827&page=1000'\n",
    "# response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "# soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# last_page = soup.select('div.paging>strong')[0].text\n",
    "# last_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid=008&date=20220827'\n",
    "# response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "# soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# naver_news_contents_data = soup.select('ul>li>dl>dd>span.lede')\n",
    "# naver_news_contents_data[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list = []\n",
    "# naver_news_url_data = soup.select('ul>li>dl>dt>a')\n",
    "# for i in naver_news_url_data:\n",
    "#     if i['href'] in list:\n",
    "#         continue\n",
    "#     else:\n",
    "#         list.append(i['href'])\n",
    "# len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list4 =[]\n",
    "# naver_news_id_data = soup.select('ul>li>dl>dd>span.writing')\n",
    "# for i in naver_news_id_data:\n",
    "#     print(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# tqdm(range(20220701, 20220832))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 만들어서 네이버 뉴스 추출하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제목 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "oid = ''\n",
    "def naver_news_title(list1, oid):\n",
    "    for date in tqdm(range(20220701, 20220832)):\n",
    "        url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&listType=summary&oid={oid}&date={date}&page=1000'\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        last_page_data = soup.select('div.paging>strong')[0]\n",
    "        last_page = int(last_page_data.text)\n",
    "        for page in range(1, last_page + 1):\n",
    "            url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&listType=summary&oid={oid}&date={date}&page={page}'\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "            naver_news_data = soup.select('ul.type06_headline>li>dl>dt>a') + soup.select('ul.type06>li>dl>dt>a')\n",
    "            for i in naver_news_data:\n",
    "                if i.select('img') == []:\n",
    "                    list1.append(i.text.strip())\n",
    "                else:\n",
    "                    continue\n",
    "    return list1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내용 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2= []\n",
    "oid= ''\n",
    "def naver_news_content(list2, oid):\n",
    "    for date in tqdm(range(20220701, 20220832)):\n",
    "        url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&listType=summary&oid={oid}&date={date}&page=1000'\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        last_page_data = soup.select('div.paging>strong')[0]\n",
    "        last_page = int(last_page_data.text)\n",
    "        for page in range(1, last_page+1):\n",
    "            url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&listType=summary&oid={oid}&date={date}&page={page}'\n",
    "            response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            naver_news_contents_data = soup.select('ul.type06_headline>li>dl>dd>span.lede') + soup.select('ul.type06>li>dl>dd>span.lede')\n",
    "            for s in naver_news_contents_data:\n",
    "                list2.append(s.text.strip())\n",
    "    return list2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스 출처 홈페이지 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 =[]\n",
    "oid=''\n",
    "def naver_news_url(list3, oid):\n",
    "    for date in tqdm(range(20220701, 20220832)):\n",
    "        url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&listType=summary&oid={oid}&date={date}&page=1000'\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        last_page_data = soup.select('div.paging>strong')[0]\n",
    "        last_page = int(last_page_data.text)\n",
    "        for page in range(1, last_page+1):\n",
    "            url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&listType=summary&oid={oid}&date={date}&page={page}'\n",
    "            response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "            soup=BeautifulSoup(response.text, 'html.parser')\n",
    "            naver_news_image_data =soup.select('ul.type06_headline>li>dl>dt>a') + soup.select('ul.type06>li>dl>dt>a')\n",
    "            for i in naver_news_image_data:\n",
    "                if i.select('img')==[]:\n",
    "                    list3.append(i['href'])\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "    return list3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스 회사 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "list4 = []\n",
    "oid=''\n",
    "def naver_news_id(list4, oid):\n",
    "    for date in tqdm(range(20220701, 20220832)):\n",
    "        url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&listType=summary&oid={oid}&date={date}&page=1000'\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        last_page_data = soup.select('div.paging>strong')[0]\n",
    "        last_page = int(last_page_data.text)\n",
    "        for page in range(1, last_page+1):\n",
    "            url = f'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&listType=summary&oid={oid}&date={date}&page={page}'\n",
    "            response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "            soup=BeautifulSoup(response.text, 'html.parser')\n",
    "            naver_news_id_data =soup.select('ul.type06_headline>li>dl>dd>span.writing') + soup.select('ul.type06>li>dl>dd>span.writing')\n",
    "            for id in naver_news_id_data:\n",
    "                list4.append(id.text)\n",
    "    return list4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&oid=008&date=20220827&page=1000'\n",
    "# response = requests.get(url, headers={'User-Agent': 'Mozilla 5.0'})\n",
    "# soup=BeautifulSoup(response.text, 'html.parser')\n",
    "# naver_news_id_data =soup.select('div>ul>li>dl>dd>span.writing')\n",
    "# print(naver_news_id_data[0].text)\n",
    "# last_page = int(soup.select('div.paging>strong')[0].text)\n",
    "# print(last_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oid = ['008', '009', '015', '023', '025']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스 제목 데이터수 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [07:54<00:00,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(naver_news_title([],'008')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스 내용 데이터 수 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [07:37<00:00,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(naver_news_content([],'008')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스 출처 데이터 수 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [08:03<00:00,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(naver_news_url([],'008')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스 회사 데이터 수 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [08:37<00:00,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(naver_news_id([],'008')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신문 회사에 대한 데이터 프레임 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [07:21<00:00,  3.37s/it]\n",
      "100%|██████████| 131/131 [07:38<00:00,  3.50s/it]\n",
      "100%|██████████| 131/131 [08:03<00:00,  3.69s/it]\n",
      "100%|██████████| 131/131 [07:39<00:00,  3.51s/it]\n"
     ]
    }
   ],
   "source": [
    "money_today_news_data = pd.DataFrame({\n",
    "    \"id\": naver_news_id([],'008'),\n",
    "    \"title\": naver_news_title([],'008'),\n",
    "    \"content\": naver_news_content([],'008'),\n",
    "    \"url\": naver_news_url([],'008')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [08:20<00:00,  3.82s/it]\n",
      "100%|██████████| 131/131 [08:56<00:00,  4.10s/it]\n",
      "100%|██████████| 131/131 [09:20<00:00,  4.28s/it]\n",
      "100%|██████████| 131/131 [09:29<00:00,  4.35s/it]\n"
     ]
    }
   ],
   "source": [
    "mail_economy_news_data = pd.DataFrame({\n",
    "    \"id\": naver_news_id([],'009'),\n",
    "    \"title\": naver_news_title([],'009'),\n",
    "    \"content\": naver_news_content([],'009'),\n",
    "    \"url\": naver_news_url([],'009')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [06:09<00:00,  2.82s/it]\n",
      "100%|██████████| 131/131 [05:58<00:00,  2.73s/it]\n",
      "100%|██████████| 131/131 [06:19<00:00,  2.90s/it]\n",
      "100%|██████████| 131/131 [06:20<00:00,  2.90s/it]\n"
     ]
    }
   ],
   "source": [
    "middle_eilbo_news_data = pd.DataFrame({\n",
    "    \"id\": naver_news_id([],'025'),\n",
    "    \"title\": naver_news_title([],'025'),\n",
    "    \"content\": naver_news_content([],'025'),\n",
    "    \"url\": naver_news_url([],'025')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [06:24<00:00,  2.94s/it]\n",
      "100%|██████████| 131/131 [05:47<00:00,  2.65s/it]\n",
      "100%|██████████| 131/131 [04:58<00:00,  2.28s/it]\n",
      "100%|██████████| 131/131 [05:52<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "chosun_eilbo_news_data = pd.DataFrame({\n",
    "    \"id\": naver_news_id([],'023'),\n",
    "    \"title\": naver_news_title([],'023'),\n",
    "    \"content\": naver_news_content([],'023'),\n",
    "    \"url\": naver_news_url([],'023')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [10:20<00:00,  4.74s/it]\n",
      "100%|██████████| 131/131 [11:12<00:00,  5.13s/it]\n",
      "100%|██████████| 131/131 [09:25<00:00,  4.31s/it]\n",
      "100%|██████████| 131/131 [10:17<00:00,  4.71s/it]\n"
     ]
    }
   ],
   "source": [
    "korean_economy_news_data = pd.DataFrame({\n",
    "    \"id\": naver_news_id([],'015'),\n",
    "    \"title\": naver_news_title([],'015'),\n",
    "    \"content\": naver_news_content([],'015'),\n",
    "    \"url\": naver_news_url([],'015')\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_today_news_data.to_csv(\"money_today.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_economy_news_data.to_csv('mail_economy.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_eilbo_news_data.to_csv('middle_eilbo.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosun_eilbo_news_data.to_csv('chosun_eilbo.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_economy_news_data.to_csv('korean_economy.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube API 이용하여 크롤링하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정으로 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from oauth2client.tools import argparser\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DEVELOPER_KEY='AIzaSyDitP67cnauWgzSvRqh0dbV9NAYMK6n5I4'\n",
    "YOUTUBE_API_SERVICE_NAME='youtube'\n",
    "YOUTUBE_API_VERSION='v3'\n",
    "\n",
    "youtube = build(\n",
    "  YOUTUBE_API_SERVICE_NAME,\n",
    "  YOUTUBE_API_VERSION,\n",
    "  developerKey=DEVELOPER_KEY\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = (\n",
    "#     youtube\n",
    "#     .commentThreads()\n",
    "#     .list(\n",
    "#       part='snippet,replies', \n",
    "#       videoId='627HBcT1jWY', \n",
    "#       maxResults=100\n",
    "#       )\n",
    "#     .execute()\n",
    "#     )\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while response = (\n",
    "#     youtube\n",
    "#     .commentThreads()\n",
    "#     .list(\n",
    "#       part='snippet,replies', \n",
    "#       videoId='eacvvczvPLo', \n",
    "#       maxResults=100\n",
    "#       )\n",
    "#     .execute()\n",
    "#     )\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=&maxResults=100&key=AIzaSyDitP67cnauWgzSvRqh0dbV9NAYMK6n5I4&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\bigdata_git\\bigdata_thunder\\bigdata1\\webcrawling.ipynb 셀 49\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/bigdata_git/bigdata_thunder/bigdata1/webcrawling.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m response\u001b[39m=\u001b[39m(\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/bigdata_git/bigdata_thunder/bigdata1/webcrawling.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m             youtube\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/bigdata_git/bigdata_thunder/bigdata1/webcrawling.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m             \u001b[39m.\u001b[39;49mcommentThreads()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/bigdata_git/bigdata_thunder/bigdata1/webcrawling.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m             \u001b[39m.\u001b[39;49mlist(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/bigdata_git/bigdata_thunder/bigdata1/webcrawling.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m             part\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msnippet,replies\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/bigdata_git/bigdata_thunder/bigdata1/webcrawling.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             videoId\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/bigdata_git/bigdata_thunder/bigdata1/webcrawling.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m             maxResults\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/bigdata_git/bigdata_thunder/bigdata1/webcrawling.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m             )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/bigdata_git/bigdata_thunder/bigdata1/webcrawling.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m.\u001b[39;49mexecute()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/bigdata_git/bigdata_thunder/bigdata1/webcrawling.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/bigdata_git/bigdata_thunder/bigdata1/webcrawling.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m list5\u001b[39m=\u001b[39m[]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/bigdata_git/bigdata_thunder/bigdata1/webcrawling.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m videoiddata\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[39melif\u001b[39;00m positional_parameters_enforcement \u001b[39m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[39m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\googleapiclient\\http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    936\u001b[0m     callback(resp)\n\u001b[0;32m    937\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[39mraise\u001b[39;00m HttpError(resp, content, uri\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muri)\n\u001b[0;32m    939\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=&maxResults=100&key=AIzaSyDitP67cnauWgzSvRqh0dbV9NAYMK6n5I4&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">"
     ]
    }
   ],
   "source": [
    "response=(\n",
    "            youtube\n",
    "            .commentThreads()\n",
    "            .list(\n",
    "            part='snippet,replies', \n",
    "            videoId='', \n",
    "            maxResults=100\n",
    "            )\n",
    "        .execute()\n",
    "        )\n",
    "list5=[]\n",
    "videoiddata=''\n",
    "def youtube_comments(list5, videoiddata):\n",
    "    while response.get('pageToken'):\n",
    "        if 'nextPageToken' in response:\n",
    "            response2=(\n",
    "                youtube\n",
    "                .commentThreads()\n",
    "                .list(\n",
    "                part='snippet,replies', \n",
    "                videoId=videoiddata, \n",
    "                pageToken=response.get('nextPageToken'),\n",
    "                maxResults=100\n",
    "                )\n",
    "            .execute()\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "    return [response2.get('items')[i].get('snippet').get('topLevelComment').get('snippet').get('textOriginal') for i in range(len(response.get('items')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = (\n",
    "    youtube\n",
    "    .commentThreads()\n",
    "    .list(\n",
    "      part='snippet,replies', \n",
    "      videoId='627HBcT1jWY', \n",
    "      maxResults=100\n",
    "      )\n",
    "    .execute()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 정보 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import xmltodict\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '03880acf9b9a1701f822dbbe25c4340eaaddfe57'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dart_information_url = f'https://opendart.fss.or.kr/api/list.json?crtfc_key={api_key}&bgn_de=20200117&end_de=20200117&corp_cls=Y&page_no=1&page_count=10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dart_information_source = requests.get(dart_information_url)\n",
    "# eval(dart_information_source.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in tree.getroot().iter('list'):\n",
    "#     print(list(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"03880acf9b9a1701f822dbbe25c4340eaaddfe57\"\n",
    "url = \"https://opendart.fss.or.kr/api/corpCode.xml\"\n",
    "\n",
    "params = {\n",
    "    \"crtfc_key\": key\n",
    "}\n",
    "resp = requests.get(url, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = io.BytesIO(resp.content)\n",
    "zfile = zipfile.ZipFile(f)\n",
    "zfile.namelist()\n",
    "xml = zfile.read(\"CORPCODE.xml\").decode(\"utf-8\")\n",
    "dict_data = xmltodict.parse(xml)\n",
    "code_lists = dict_data.get('result').get('list')\n",
    "list1 = []\n",
    "for code_list in code_lists:\n",
    "    list1.append(code_list.get('corp_code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'aad8902f062d010bc147854f95f914ff684f3092'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_20_list = ['00126380','01515323', '00164779', '00877059', '00356361', '00164742', '00126362', '00266961', '00106641', '00258801', '00413046', '00149655', '00155319', '00164788', '00688996', '00382199', '00631518', '00181712', '00401731', '00126256']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기업 현황 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def industry_economics(corp_code):\n",
    "    api_key = 'aad8902f062d010bc147854f95f914ff684f3092'\n",
    "    url = f'https://opendart.fss.or.kr/api/company.json?crtfc_key={api_key}&corp_code={corp_code}'\n",
    "    response = requests.get(url)\n",
    "    return eval(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>message</th>\n",
       "      <th>corp_code</th>\n",
       "      <th>corp_name</th>\n",
       "      <th>corp_name_eng</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>stock_code</th>\n",
       "      <th>ceo_nm</th>\n",
       "      <th>corp_cls</th>\n",
       "      <th>jurir_no</th>\n",
       "      <th>bizr_no</th>\n",
       "      <th>adres</th>\n",
       "      <th>hm_url</th>\n",
       "      <th>ir_url</th>\n",
       "      <th>phn_no</th>\n",
       "      <th>fax_no</th>\n",
       "      <th>induty_code</th>\n",
       "      <th>est_dt</th>\n",
       "      <th>acc_mt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>기업</th>\n",
       "      <td>000</td>\n",
       "      <td>정상</td>\n",
       "      <td>00432403</td>\n",
       "      <td>한라판지(주)</td>\n",
       "      <td>HANLA PARKING CO.,LTD</td>\n",
       "      <td>한라판지</td>\n",
       "      <td></td>\n",
       "      <td>정우석</td>\n",
       "      <td>E</td>\n",
       "      <td>2201110019993</td>\n",
       "      <td>6168120149</td>\n",
       "      <td>제주특별자치도 북제주군 한림읍 상명리 587</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>064-796-8001</td>\n",
       "      <td>064-796-8003</td>\n",
       "      <td>17123</td>\n",
       "      <td>19970601</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status message corp_code corp_name          corp_name_eng stock_name  \\\n",
       "기업    000      정상  00432403   한라판지(주)  HANLA PARKING CO.,LTD       한라판지   \n",
       "\n",
       "   stock_code ceo_nm corp_cls       jurir_no     bizr_no  \\\n",
       "기업               정우석        E  2201110019993  6168120149   \n",
       "\n",
       "                       adres hm_url ir_url        phn_no        fax_no  \\\n",
       "기업  제주특별자치도 북제주군 한림읍 상명리 587                064-796-8001  064-796-8003   \n",
       "\n",
       "   induty_code    est_dt acc_mt  \n",
       "기업       17123  19970601     12  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(industry_economics('00432403'), index=['기업'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for corp in tqdm(list1[0:5]):\n",
    "    corp_data = pd.DataFrame(industry_economics(corp),index=['기업'])\n",
    "    corp_data.to_csv('middle_eilbo.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = []\n",
    "message = []\n",
    "corp_name = []\n",
    "corp_name_eng = []\n",
    "stock_name = []\n",
    "stock_code = []\n",
    "ceo_nm = []\n",
    "corp_cls = []\n",
    "jurir_no = []\n",
    "bizr_no = []\n",
    "adres = []\n",
    "hm_url = []\n",
    "ir_url = []\n",
    "phn_no = []\n",
    "fax_no = []\n",
    "induty_code = []\n",
    "est_dt = []\n",
    "acc_mt = []\n",
    "for corp in tqdm(corp_20_list):\n",
    "    status.append(industry_economics(corp).get('status'))\n",
    "    message.append(industry_economics(corp).get('message'))\n",
    "    corp_name.append(industry_economics(corp).get('corp_name'))\n",
    "    corp_name_eng.append(industry_economics(corp).get('corp_name_eng'))\n",
    "    stock_name.append(industry_economics(corp).get('stock_name'))\n",
    "    stock_code.append(industry_economics(corp).get('stock_code'))\n",
    "    ceo_nm.append(industry_economics(corp).get('ceo_nm'))\n",
    "    corp_cls.append(industry_economics(corp).get('corp_cls'))\n",
    "    jurir_no.append(industry_economics(corp).get('jurir_no'))\n",
    "    bizr_no.append(industry_economics(corp).get('bizr_no'))\n",
    "    adres.append(industry_economics(corp).get('adres'))\n",
    "    hm_url.append(industry_economics(corp).get('hm_url'))\n",
    "    ir_url.append(industry_economics(corp).get('ir_url'))\n",
    "    phn_no.append(industry_economics(corp).get('phn_no'))\n",
    "    fax_no.append(industry_economics(corp).get('fax_no'))\n",
    "    induty_code.append(industry_economics(corp).get('induty_code'))\n",
    "    est_dt.append(industry_economics(corp).get('est_dt'))\n",
    "    acc_mt.append(industry_economics(corp).get('acc_mt'))\n",
    "corp_20_data = pd.DataFrame({'status': status,\n",
    "'message': message,\n",
    "'corp_name': corp_name,\n",
    "'corp_name_eng': corp_name_eng,\n",
    "'stock_name': stock_name,\n",
    "'stock_code': stock_code,\n",
    "'ceo_nm': ceo_nm,\n",
    "'corp_cls': corp_cls,\n",
    "'jurir_no': jurir_no,\n",
    "'bizr_no': bizr_no,\n",
    "'adres': adres,\n",
    "'hm_url': hm_url,\n",
    "'ir_url': ir_url,\n",
    "'phn_no': phn_no,\n",
    "'fax_no': fax_no,\n",
    "'induty_code': induty_code,\n",
    "'est_dt': est_dt,\n",
    "'acc_mt': acc_mt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_20_data.to_csv('기업개황.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 재무 제표 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_code = ''\n",
    "def dart_economy(corp_code):\n",
    "    api_key = 'aad8902f062d010bc147854f95f914ff684f3092'\n",
    "    search_url = f'https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json?crtfc_key={api_key}&corp_code={corp_code}&bsns_year=2021&reprt_code=11011&fs_div=CFS'\n",
    "    search_response = requests.get(search_url)\n",
    "    search_json = eval(search_response.text)\n",
    "    if search_json.get('list') == None:\n",
    "        return []\n",
    "    else:\n",
    "        return eval(search_response.text).get('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcept_no = []\n",
    "reprt_code = []\n",
    "bsns_year = []\n",
    "sj_div = []\n",
    "sj_nm = []\n",
    "account_id = []\n",
    "account_nm = []\n",
    "account_detail = []\n",
    "thstrm_nm = []\n",
    "thstrm_amount = []\n",
    "ord = []\n",
    "currency = []\n",
    "for number in tqdm(corp_20_list):\n",
    "    for i in dart_economy(number):\n",
    "        rcept_no.append(i.get('rcept_no'))\n",
    "        reprt_code.append(i.get('reprt_code'))\n",
    "        bsns_year.append(i.get('bsns_year'))\n",
    "        sj_div.append(i.get('sj_div'))\n",
    "        account_id.append(i.get('account_id'))\n",
    "        account_nm.append(i.get('account_nm'))\n",
    "        account_detail.append(i.get('account_detail'))\n",
    "        thstrm_nm.append(i.get('thstrm_nm'))\n",
    "        thstrm_amount.append(i.get('thstrm_amount'))\n",
    "        ord.append(i.get('ord'))\n",
    "        currency.append(i.get('currency'))\n",
    "dart_20_economy_data = pd.DataFrame({\n",
    "    'rcept_no' : rcept_no,\n",
    "    'reprt_code' : reprt_code,\n",
    "    'bsns_year' : bsns_year,\n",
    "    'sj_div' : sj_div,\n",
    "    'account_id' : account_id,\n",
    "    'account_nm' : account_nm,\n",
    "    'account_detail' : account_detail,\n",
    "    'thstrm_nm' : thstrm_nm,\n",
    "    'thstrm_amount' : thstrm_amount,\n",
    "    'ord' : ord,\n",
    "    'currency' : currency\n",
    "    })\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dart_20_economy_data.to_csv('재무제표.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
