{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAVER 뉴스 데이터를 이용하여서 데이터 추출하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup, Requests, Pandas 모듈 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터베이스 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스별 데이터베이스 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosun_eilbo_database = pd.read_csv(r'C:\\bigdata_git\\bigdata_thunder\\bigdata1\\chosun_eilbo.csv')\n",
    "korean_economy_database = pd.read_csv(r'C:\\bigdata_git\\bigdata_thunder\\bigdata1\\korean_economy.csv')\n",
    "mail_economy_database = pd.read_csv(r'C:\\bigdata_git\\bigdata_thunder\\bigdata1\\mail_economy.csv')\n",
    "midlle_eilbo_database = pd.read_csv(r'C:\\bigdata_git\\bigdata_thunder\\bigdata1\\middle_eilbo.csv')\n",
    "money_today_database = pd.read_csv(r'C:\\bigdata_git\\bigdata_thunder\\bigdata1\\money_today.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터베이스 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>판다는 언제부터 대나무만 먹었을까? 600만년 전 화석 봤더니…</td>\n",
       "      <td>통통한 몸집과 어울리지 않게 대나무를 주식으로 하는 판다. 이런 판다의 독특한 식성...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이준석 변호인 징계요청 기각… 경기변호사회 “수사결과 봐야”</td>\n",
       "      <td>“가세연의 이준석 녹취는 일부 삭제된 것” 경기중앙지방변호사회가 한 보수단체가 제기...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>박지현 “이광재가 내 배후? 어리면 배후 있을 거라는 꼰대식 사고”</td>\n",
       "      <td>비대위원장직 자진사퇴 후 한 달 만에 공개행사 참석 이재명 전당대회 출마와 민형배 ...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>野 당권주자들 “검수완박 성급했다” 이제와서 반성 모드</td>\n",
       "      <td>강병원 “진영 논리서 벗어나야” 박용진 “상식 복원하는 게 혁신” 꼼수 탈당한 민형...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“먹으니 시야 흐려져” 시누이 부부 음식에 메탄올 넣은 30대여성</td>\n",
       "      <td>시누이 부부가 먹을 음식에 유독성 물질을 넣은 30대 여성이 특수상해 혐의로 경찰에...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13688</th>\n",
       "      <td>람보르기니 몰고 온 죄… 러 슈퍼카 차주들, 수갑 찬 채 끌려갔다</td>\n",
       "      <td>러시아에서 값비싼 슈퍼카를 몰던 차주들이 무더기로 경찰에 체포되는 일이 발생했다. ...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13689</th>\n",
       "      <td>10세 세계 최연소 트랜스젠더 모델…패션계가 주목</td>\n",
       "      <td>세계에서 가장 어린 트랜스젠더 모델인 미국 소녀 노엘라 맥마허(10)가 패션계의 주...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13690</th>\n",
       "      <td>[수요동물원] 살아있는 벌새의 뇌를… 소름 끼치는 사마귀의 먹방</td>\n",
       "      <td>곤충만 먹는줄 알았더니 개구리·도마뱀·새까지 먹어치워 짝짓기 중 동족포식하는 ‘이 ...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13691</th>\n",
       "      <td>[김한수의 오마이갓] 막 오른 ‘서울-로마 두 추기경 시대’</td>\n",
       "      <td>한국 천주교계에 ‘서울·로마 두 추기경 시대’의 막이 올랐습니다. 지난 27일(현지...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13692</th>\n",
       "      <td>[차현진의 돈과 세상] [86] 탕평책</td>\n",
       "      <td>베토벤이 청력을 잃어 불우했다고 하지만, 사실 인복은 많았다. 그는 커피를 끓이기 ...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13693 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  \\\n",
       "0        판다는 언제부터 대나무만 먹었을까? 600만년 전 화석 봤더니…   \n",
       "1          이준석 변호인 징계요청 기각… 경기변호사회 “수사결과 봐야”   \n",
       "2      박지현 “이광재가 내 배후? 어리면 배후 있을 거라는 꼰대식 사고”   \n",
       "3             野 당권주자들 “검수완박 성급했다” 이제와서 반성 모드   \n",
       "4       “먹으니 시야 흐려져” 시누이 부부 음식에 메탄올 넣은 30대여성   \n",
       "...                                      ...   \n",
       "13688   람보르기니 몰고 온 죄… 러 슈퍼카 차주들, 수갑 찬 채 끌려갔다   \n",
       "13689            10세 세계 최연소 트랜스젠더 모델…패션계가 주목   \n",
       "13690    [수요동물원] 살아있는 벌새의 뇌를… 소름 끼치는 사마귀의 먹방   \n",
       "13691      [김한수의 오마이갓] 막 오른 ‘서울-로마 두 추기경 시대’   \n",
       "13692                  [차현진의 돈과 세상] [86] 탕평책   \n",
       "\n",
       "                                                 content  \\\n",
       "0      통통한 몸집과 어울리지 않게 대나무를 주식으로 하는 판다. 이런 판다의 독특한 식성...   \n",
       "1      “가세연의 이준석 녹취는 일부 삭제된 것” 경기중앙지방변호사회가 한 보수단체가 제기...   \n",
       "2      비대위원장직 자진사퇴 후 한 달 만에 공개행사 참석 이재명 전당대회 출마와 민형배 ...   \n",
       "3      강병원 “진영 논리서 벗어나야” 박용진 “상식 복원하는 게 혁신” 꼼수 탈당한 민형...   \n",
       "4      시누이 부부가 먹을 음식에 유독성 물질을 넣은 30대 여성이 특수상해 혐의로 경찰에...   \n",
       "...                                                  ...   \n",
       "13688  러시아에서 값비싼 슈퍼카를 몰던 차주들이 무더기로 경찰에 체포되는 일이 발생했다. ...   \n",
       "13689  세계에서 가장 어린 트랜스젠더 모델인 미국 소녀 노엘라 맥마허(10)가 패션계의 주...   \n",
       "13690  곤충만 먹는줄 알았더니 개구리·도마뱀·새까지 먹어치워 짝짓기 중 동족포식하는 ‘이 ...   \n",
       "13691  한국 천주교계에 ‘서울·로마 두 추기경 시대’의 막이 올랐습니다. 지난 27일(현지...   \n",
       "13692  베토벤이 청력을 잃어 불우했다고 하지만, 사실 인복은 많았다. 그는 커피를 끓이기 ...   \n",
       "\n",
       "                                                     url  \n",
       "0      https://n.news.naver.com/mnews/article/023/000...  \n",
       "1      https://n.news.naver.com/mnews/article/023/000...  \n",
       "2      https://n.news.naver.com/mnews/article/023/000...  \n",
       "3      https://n.news.naver.com/mnews/article/023/000...  \n",
       "4      https://n.news.naver.com/mnews/article/023/000...  \n",
       "...                                                  ...  \n",
       "13688  https://n.news.naver.com/mnews/article/023/000...  \n",
       "13689  https://n.news.naver.com/mnews/article/023/000...  \n",
       "13690  https://n.news.naver.com/mnews/article/023/000...  \n",
       "13691  https://n.news.naver.com/mnews/article/023/000...  \n",
       "13692  https://n.news.naver.com/mnews/article/023/000...  \n",
       "\n",
       "[13693 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosun_eilbo_database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표본별 뉴스 제목중 하나 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'판다는 언제부터 대나무만 먹었을까? 600만년 전 화석 봤더니…'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosun_eilbo_database['title'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스 출처 홈페이지 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://n.news.naver.com/mnews/article/023/0003701167'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosun_eilbo_database['url'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 깃허브 오픈소스 이용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화로 바꾸는 파일 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['판다는 언제부터 대나무만 먹었을까?', '600만년 전 화석 봤더니…']\n",
      "[('판다는 언제부터 대나무만 먹었을까?', '$'), ('600만년 전 화석 봤더니…', 'CD')]\n"
     ]
    }
   ],
   "source": [
    "print(kss.split_sentences(chosun_eilbo_database['title'][0]))\n",
    "print(pos_tag(kss.split_sentences(chosun_eilbo_database['title'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['판다', '는', '언제', '부터', '대나무', '만', '먹', '었', '을까', '?', '600', '만', '년', '전', '화석', '보', '았', '더니', '…']\n"
     ]
    }
   ],
   "source": [
    "print(okt.morphs(chosun_eilbo_database['title'][0]) and kkma.morphs(chosun_eilbo_database['title'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url 홈페이지 BeautifulSoup을이용해서 소스에 있는 내용 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36\"}\n",
    "response_0 = requests.get(chosun_eilbo_database[\"url\"][0], headers=headers)\n",
    "soup_0 = BeautifulSoup(response_0.text, 'html.parser')\n",
    "content_0_data = soup_0.find('div', {\"id\" : \"dic_area\"}).get_text()\n",
    "content_0_data = content_0_data.replace('\\n','').replace('\\t','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_data = okt.morphs(content_0_data) and kkma.morphs(content_0_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표제어 제거하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\82105\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\82105\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "표제어 추출 후 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n",
      "die\n",
      "watch\n",
      "have\n",
      "어간 추출 전 : ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n",
      "어간 추출 후 : ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n",
      "어간 추출 전 : ['formalize', 'allowance', 'electricical']\n",
      "어간 추출 후 : ['formal', 'allow', 'electric']\n",
      "어간 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "포터 스테머의 어간 추출 후: ['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n",
      "랭커스터 스테머의 어간 추출 후: ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
     ]
    }
   ],
   "source": [
    "from stemming_lemmatization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "\n",
      "['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
     ]
    }
   ],
   "source": [
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "print(words)\n",
    "print()\n",
    "print([lemmatizer.lemmatize(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for word in words_data:\n",
    "#     print(lemmatizer.lemmatize(word))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스 내용항목 중 한국어 불용어 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\82105\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\82105\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "불용어 10개 출력 : ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n",
      "불용어 제거 전 : ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
      "불용어 제거 후 : ['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
      "불용어 제거 전 : []\n",
      "불용어 제거 후 : ['고기', '하면', '.', '고기', '라고', '다', '아니거든', '.', '예컨대', '삼겹살', '을', '중요한', '있지', '.']\n"
     ]
    }
   ],
   "source": [
    "from remove_stopwords import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 전 : ['팔', 'ㄴ다', '.', '/', '픽', '사', '베이', '통', '통', '하', 'ㄴ', '몸집', '과', '어울리', '지', '않', '게', '대나무', '를', '주식', '으로', '하', '는', '판다', '.', '이런', '판다', '의', '독특', '하', 'ㄴ', '식성', '이', '최소', '600', '만', '년', '전', '부터', '이어지', '었', '을', '가능성', '이', '있', '다는', '연구', '결과', '가', '나오', '았', '다', '.', '1', '일', '(', '현지', '시각', ')', 'CNN', '등', '외신', '에', '따르', '면', '미국', '로스', '앤', '젤', '레스', '자연사', '박물관', '의', '왕', '샬', '오', '밍', '박사', '연구', '팀', '은', '최근', '약', '600', '만', '년', '전', '자이언트', '판다', '조', '상인', '아이', 'ㄹ', '루', '락', '토스', '(', 'Ailurarctos', ')', '화석', '을', '분석', '하', 'ㄴ', '결과', ',', '대나무', '를', '잡', '는', '데', '쓰이', '는', '‘', '가짜', '엄지', '’', '가', '아', '존재', '하', '었', '다고', '밝히', '었', '다', '.', '이', '화석', '은', '중국', '남부', '윈난성', '자오퉁', '시의', '슈', '이', '탕', '바', '지역', '에서', '발굴', '되', '었', '다', '.', '약', '600', '만', '년', '전', '살', '았', '더', 'ㄴ', '고대', '판다', '아이', 'ㄹ', '루', '락', '토스', '의', '것', '이', '다', '.', '눈여겨보', 'ㄹ', '것', '은', '손목', '부위', '에서', '발견', '되', 'ㄴ', '돌출', '뼈', '이', '다', '.', '연구', '팀', '은', '바로', '이', '뼈', '가', '자이언트', '판다', '가', '가지', 'ㄴ', '여섯', '번째', '손가락', '일명', '‘', '가짜', '엄지', '’', '라고', '말하', '었', '다', '.', '판다', '의', '가짜', '엄지', '.', '/', '뉴', '시스', '판다', '의', '가짜', '엄지', '는', '대나무', '를', '보다', '쉽', '게', '잡', '을', '수', '있', '도록', '하', '는', '데', '쓰이', 'ㄴ다', '.', '판', '다그', '아', '초식', '동물', '로', '진화', '하', '는', '데', '중추적', '이', 'ㄴ', '역할', '을', '하', '었', '을', '것', '으로', '전문가', '들', '은', '보', '고', '있', '다', '.', '그동안', '이', '같', '은', '진화', '적', '적응', '은', '약', '15', '만', '년', '전', '이', 'ㄴ', '비교적', '최근', '이루', '어', '지', 'ㄴ', '것', '으로', '여기', '어', '지', '어', '오', '았', '는데', ',', '이번', '연구가', '무려', '600', '만', '년', '을', '거스르', '어', '올라가', 'ㄴ다는', '것', '을', '증명', '해내', 'ㄴ', '셈', '이', '다', '.', '화석', '에서', '발견', '되', 'ㄴ', '가짜', '엄지', '는', '현대', '판다', '의', '것', '보다', '더', '길', 'ㄴ', '길이', '의', '직선', '모양', '을', '하', '고', '있', '었', '다', '.', '연구', '팀', '은', '“', '가짜', '엄지', '는', '대나무', '를', '잡', '고', '뜯어먹', '을', '때', '는', '물론', '다음', '먹이', '를', '찾', '아', '걸어가', 'ㄹ', '때', '몸무게', '를', '지탱', '하', '는', '용도', '로', '도', '쓰이', '는데', ',', '이', '과정', '에서', '길', 'ㄴ', '뼈', '가', '짧', '은', '갈고리', '형', '으로', '진화', '하', '게', '되', 'ㄴ', '것', '”', '이', '라고', '분석', '하', '었', '다', '.', '왕', '박사', '는', '“', '대나무', '를', '먹', '기', '좋', '게', '쪼개', '기', '위하', '어', '줄기', '를', '단단히', '붙잡', '는', '것', '은', '많', '은', '양', '의', '대나무', '를', '먹', '는', '데', '가장', '중요', '하', 'ㄴ', '적응', '”', '이', '라며', '“', '육식성', '조상', '에서', '진화', '하', '어', '대나무', '만', '먹', '는', '종', '으로', '바뀌', 'ㄴ', '판다', '는', '많', '은', '장애', '를', '넘', '어야', '하', '었', '을', '것', '이', '고', '가짜', '엄지', '는', '그중', '가장', '놀랍', 'ㄴ', '진화', '”', '라고', '설명', '하', '었', '다', '.']\n",
      "\n",
      "불용어 제거 후 : ['ㄴ다', '.', '/', '픽', '베이', '통', '통', 'ㄴ', '몸집', '어울리', '지', '않', '게', '대나무', '주식', '는', '판다', '.', '판다', '독특', 'ㄴ', '식성', '최소', '600', '만', '전', '이어지', '었', '가능성', '있', '다는', '연구', '결과', '나오', '았', '다', '.', '1', '(', '현지', ')', 'CNN', '외신', '따르', '면', '미국', '로스', '앤', '젤', '레스', '자연사', '박물관', '왕', '샬', '밍', '박사', '연구', '팀', '은', '최근', '약', '600', '만', '전', '자이언트', '판다', '조', '상인', 'ㄹ', '루', '락', '토스', '(', 'Ailurarctos', ')', '화석', '분석', 'ㄴ', '결과', ',', '대나무', '잡', '는', '데', '쓰이', '는', '‘', '가짜', '엄지', '’', '존재', '었', '다고', '밝히', '었', '다', '.', '화석', '은', '중국', '남부', '윈난성', '자오퉁', '시의', '슈', '탕', '바', '지역', '발굴', '되', '었', '다', '.', '약', '600', '만', '전', '살', '았', '더', 'ㄴ', '고대', '판다', 'ㄹ', '루', '락', '토스', '다', '.', '눈여겨보', 'ㄹ', '은', '손목', '부위', '발견', '되', 'ㄴ', '돌출', '뼈', '다', '.', '연구', '팀', '은', '뼈', '자이언트', '판다', '가지', 'ㄴ', '번째', '손가락', '일명', '‘', '가짜', '엄지', '’', '라고', '말하', '었', '다', '.', '판다', '가짜', '엄지', '.', '/', '뉴', '시스', '판다', '가짜', '엄지', '는', '대나무', '보다', '쉽', '게', '잡', '수', '있', '도록', '는', '데', '쓰이', 'ㄴ다', '.', '판', '다그', '초식', '동물', '진화', '는', '데', '중추적', 'ㄴ', '역할', '었', '전문가', '은', '보', '고', '있', '다', '.', '그동안', '같', '은', '진화', '적', '적응', '은', '약', '15', '만', '전', 'ㄴ', '최근', '이루', '지', 'ㄴ', '지', '았', '는데', ',', '연구가', '무려', '600', '만', '거스르', '올라가', 'ㄴ다는', '증명', '해내', 'ㄴ', '셈', '다', '.', '화석', '발견', '되', 'ㄴ', '가짜', '엄지', '는', '현대', '판다', '보다', '더', '길', 'ㄴ', '길이', '직선', '모양', '고', '있', '었', '다', '.', '연구', '팀', '은', '“', '가짜', '엄지', '는', '대나무', '잡', '고', '뜯어먹', '는', '먹이', '찾', '걸어가', 'ㄹ', '몸무게', '지탱', '는', '용도', '도', '쓰이', '는데', ',', '과정', '길', 'ㄴ', '뼈', '짧', '은', '갈고리', '형', '진화', '게', '되', 'ㄴ', '”', '라고', '분석', '었', '다', '.', '왕', '박사', '는', '“', '대나무', '먹', '기', '좋', '게', '쪼개', '기', '위하', '줄기', '단단히', '붙잡', '는', '은', '많', '은', '양', '대나무', '먹', '는', '데', '가장', '중요', 'ㄴ', '적응', '”', '라며', '“', '육식성', '조상', '진화', '대나무', '만', '먹', '는', '종', '바뀌', 'ㄴ', '판다', '는', '많', '은', '장애', '넘', '어야', '었', '고', '가짜', '엄지', '는', '그중', '가장', '놀랍', 'ㄴ', '진화', '”', '라고', '설명', '었', '다', '.']\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:\\\\bigdata_git\\\\bigdata_thunder\\\\bigdata2\\\\korean_stopwords.txt\", \"r\", encoding=\"UTF-8\") as stopwords:\n",
    "    stopwords_list = stopwords.read().split('\\n')\n",
    "print('불용어 제거 전 :',words_data) \n",
    "print()\n",
    "print('불용어 제거 후 :',korean_change_no_stop_words(words_data, stopwords_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㄴ다./픽베이통통ㄴ몸집어울리지않게대나무주식는판다.판다독특ㄴ식성최소600만전이어지었가능성있다는연구결과나오았다.1(현지)CNN외신따르면미국로스앤젤레스자연사박물관왕샬밍박사연구팀은최근약600만전자이언트판다조상인ㄹ루락토스(Ailurarctos)화석분석ㄴ결과,대나무잡는데쓰이는‘가짜엄지’존재었다고밝히었다.화석은중국남부윈난성자오퉁시의슈탕바지역발굴되었다.약600만전살았더ㄴ고대판다ㄹ루락토스다.눈여겨보ㄹ은손목부위발견되ㄴ돌출뼈다.연구팀은뼈자이언트판다가지ㄴ번째손가락일명‘가짜엄지’라고말하었다.판다가짜엄지./뉴시스판다가짜엄지는대나무보다쉽게잡수있도록는데쓰이ㄴ다.판다그초식동물진화는데중추적ㄴ역할었전문가은보고있다.그동안같은진화적적응은약15만전ㄴ최근이루지ㄴ지았는데,연구가무려600만거스르올라가ㄴ다는증명해내ㄴ셈다.화석발견되ㄴ가짜엄지는현대판다보다더길ㄴ길이직선모양고있었다.연구팀은“가짜엄지는대나무잡고뜯어먹는먹이찾걸어가ㄹ몸무게지탱는용도도쓰이는데,과정길ㄴ뼈짧은갈고리형진화게되ㄴ”라고분석었다.왕박사는“대나무먹기좋게쪼개기위하줄기단단히붙잡는은많은양대나무먹는데가장중요ㄴ적응”라며“육식성조상진화대나무만먹는종바뀌ㄴ판다는많은장애넘어야었고가짜엄지는그중가장놀랍ㄴ진화”라고설명었다.\n"
     ]
    }
   ],
   "source": [
    "new_content_1 ='' \n",
    "for i in korean_change_no_stop_words(words_data, stopwords_list):\n",
    "    new_content_1 += i\n",
    "print(new_content_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular expression   A regular expression  regex or regexp     sometimes called a rational expression        is  in theoretical computer science and formal language theory  a sequence of characters that define a search pattern \n",
      "['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n",
      "[\"Don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name,', 'Mr.', \"Jone's\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
     ]
    }
   ],
   "source": [
    "from regular_expression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 3), match='a.c'>\n"
     ]
    }
   ],
   "source": [
    "r = re.compile(\"a.c\")\n",
    "print(r.search(\"a.c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
