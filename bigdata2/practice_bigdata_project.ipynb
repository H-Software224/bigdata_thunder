{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAVER 뉴스 데이터를 이용하여서 데이터 추출하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup, Requests, Pandas 모듈 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터베이스 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스별 데이터베이스 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosun_eilbo_database = pd.read_csv(r'C:\\Users\\user\\Documents\\github\\bigdata_thunder\\bigdata1\\chosun_eilbo.csv', encoding='cp949')\n",
    "# korean_economy_database = pd.read_csv(r'C:\\Users\\user\\Documents\\github\\bigdata_thunder\\bigdata1\\korean_economy.csv', encoding='cp949')\n",
    "# mail_economy_database = pd.read_csv(r'C:\\Users\\user\\Documents\\github\\bigdata_thunder\\bigdata1\\mail_economy.csv', encoding='cp949')\n",
    "# midlle_eilbo_database = pd.read_csv(r'C:\\Users\\user\\Documents\\github\\bigdata_thunder\\bigdata1\\middle_eilbo.csv', encoding='cp949')\n",
    "# money_today_database = pd.read_csv(r'C:\\Users\\user\\Documents\\github\\bigdata_thunder\\bigdata1\\money_today.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "데이터베이스 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>판다는 언제부터 대나무만 먹었을까? 600만년 전 화석 봤더니…</td>\n",
       "      <td>통통한 몸집과 어울리지 않게 대나무를 주식으로 하는 판다. 이런 판다의 독특한 식성...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이준석 변호인 징계요청 기각… 경기변호사회 “수사결과 봐야”</td>\n",
       "      <td>“가세연의 이준석 녹취는 일부 삭제된 것” 경기중앙지방변호사회가 한 보수단체가 제기...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>박지현 “이광재가 내 배후? 어리면 배후 있을 거라는 꼰대식 사고”</td>\n",
       "      <td>비대위원장직 자진사퇴 후 한 달 만에 공개행사 참석 이재명 전당대회 출마와 민형배 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>野 당권주자들 “검수완박 성급했다” 이제와서 반성 모드</td>\n",
       "      <td>강병원 “진영 논리서 벗어나야” 박용진 “상식 복원하는 게 혁신” 꼼수 탈당한 민형...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“먹으니 시야 흐려져” 시누이 부부 음식에 메탄올 넣은 30대여성</td>\n",
       "      <td>시누이 부부가 먹을 음식에 유독성 물질을 넣은 30대 여성이 특수상해 혐의로 경찰에...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13688</th>\n",
       "      <td>람보르기니 몰고 온 죄… 러 슈퍼카 차주들, 수갑 찬 채 끌려갔다</td>\n",
       "      <td>러시아에서 값비싼 슈퍼카를 몰던 차주들이 무더기로 경찰에 체포되는 일이 발생했다. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13689</th>\n",
       "      <td>10세 세계 최연소 트랜스젠더 모델…패션계가 주목</td>\n",
       "      <td>세계에서 가장 어린 트랜스젠더 모델인 미국 소녀 노엘라 맥마허(10)가 패션계의 주...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13690</th>\n",
       "      <td>[수요동물원] 살아있는 벌새의 뇌를… 소름 끼치는 사마귀의 먹방</td>\n",
       "      <td>곤충만 먹는줄 알았더니 개구리·도마뱀·새까지 먹어치워 짝짓기 중 동족포식하는 ‘이 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13691</th>\n",
       "      <td>[김한수의 오마이갓] 막 오른 ‘서울-로마 두 추기경 시대’</td>\n",
       "      <td>한국 천주교계에 ‘서울·로마 두 추기경 시대’의 막이 올랐습니다. 지난 27일(현지...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13692</th>\n",
       "      <td>[차현진의 돈과 세상] [86] 탕평책</td>\n",
       "      <td>베토벤이 청력을 잃어 불우했다고 하지만, 사실 인복은 많았다. 그는 커피를 끓이기 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13693 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  \\\n",
       "0        판다는 언제부터 대나무만 먹었을까? 600만년 전 화석 봤더니…   \n",
       "1          이준석 변호인 징계요청 기각… 경기변호사회 “수사결과 봐야”   \n",
       "2      박지현 “이광재가 내 배후? 어리면 배후 있을 거라는 꼰대식 사고”   \n",
       "3             野 당권주자들 “검수완박 성급했다” 이제와서 반성 모드   \n",
       "4       “먹으니 시야 흐려져” 시누이 부부 음식에 메탄올 넣은 30대여성   \n",
       "...                                      ...   \n",
       "13688   람보르기니 몰고 온 죄… 러 슈퍼카 차주들, 수갑 찬 채 끌려갔다   \n",
       "13689            10세 세계 최연소 트랜스젠더 모델…패션계가 주목   \n",
       "13690    [수요동물원] 살아있는 벌새의 뇌를… 소름 끼치는 사마귀의 먹방   \n",
       "13691      [김한수의 오마이갓] 막 오른 ‘서울-로마 두 추기경 시대’   \n",
       "13692                  [차현진의 돈과 세상] [86] 탕평책   \n",
       "\n",
       "                                                 content  label  \\\n",
       "0      통통한 몸집과 어울리지 않게 대나무를 주식으로 하는 판다. 이런 판다의 독특한 식성...      0   \n",
       "1      “가세연의 이준석 녹취는 일부 삭제된 것” 경기중앙지방변호사회가 한 보수단체가 제기...      0   \n",
       "2      비대위원장직 자진사퇴 후 한 달 만에 공개행사 참석 이재명 전당대회 출마와 민형배 ...      0   \n",
       "3      강병원 “진영 논리서 벗어나야” 박용진 “상식 복원하는 게 혁신” 꼼수 탈당한 민형...      0   \n",
       "4      시누이 부부가 먹을 음식에 유독성 물질을 넣은 30대 여성이 특수상해 혐의로 경찰에...      0   \n",
       "...                                                  ...    ...   \n",
       "13688  러시아에서 값비싼 슈퍼카를 몰던 차주들이 무더기로 경찰에 체포되는 일이 발생했다. ...      0   \n",
       "13689  세계에서 가장 어린 트랜스젠더 모델인 미국 소녀 노엘라 맥마허(10)가 패션계의 주...      0   \n",
       "13690  곤충만 먹는줄 알았더니 개구리·도마뱀·새까지 먹어치워 짝짓기 중 동족포식하는 ‘이 ...      0   \n",
       "13691  한국 천주교계에 ‘서울·로마 두 추기경 시대’의 막이 올랐습니다. 지난 27일(현지...      0   \n",
       "13692  베토벤이 청력을 잃어 불우했다고 하지만, 사실 인복은 많았다. 그는 커피를 끓이기 ...      0   \n",
       "\n",
       "                                                     url  \n",
       "0      https://n.news.naver.com/mnews/article/023/000...  \n",
       "1      https://n.news.naver.com/mnews/article/023/000...  \n",
       "2      https://n.news.naver.com/mnews/article/023/000...  \n",
       "3      https://n.news.naver.com/mnews/article/023/000...  \n",
       "4      https://n.news.naver.com/mnews/article/023/000...  \n",
       "...                                                  ...  \n",
       "13688  https://n.news.naver.com/mnews/article/023/000...  \n",
       "13689  https://n.news.naver.com/mnews/article/023/000...  \n",
       "13690  https://n.news.naver.com/mnews/article/023/000...  \n",
       "13691  https://n.news.naver.com/mnews/article/023/000...  \n",
       "13692  https://n.news.naver.com/mnews/article/023/000...  \n",
       "\n",
       "[13693 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosun_eilbo_database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표본별 뉴스 제목중 하나 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'판다는 언제부터 대나무만 먹었을까? 600만년 전 화석 봤더니…'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosun_eilbo_database['title'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스 출처 홈페이지 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://n.news.naver.com/mnews/article/023/0003701167'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosun_eilbo_database['url'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 깃허브 오픈소스 이용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화로 바꾸는 파일 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ git clone https://github.com/ukairia777/tensorflow-nlp-tutorial.git\n",
    "# $ git clone https://github.com/haven-jeon/PyKoSpacing.git\n",
    "# $ git clone https://github.com/ssut/py-hanspell.git\n",
    "# %pip install soynlp\n",
    "# %pip install customized_konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kss in c:\\users\\user\\anaconda3\\lib\\site-packages (3.6.4)\n",
      "Requirement already satisfied: emoji==1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from kss) (1.2.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\user\\anaconda3\\lib\\site-packages (from kss) (8.14.0)\n",
      "Requirement already satisfied: regex in c:\\users\\user\\anaconda3\\lib\\site-packages (from kss) (2022.3.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\user\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (1.21.5)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (4.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soynlp in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0.493)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from soynlp) (1.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: scipy>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from soynlp) (1.7.3)\n",
      "Requirement already satisfied: psutil>=5.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from soynlp) (5.8.0)\n",
      "Requirement already satisfied: numpy>=1.12.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from soynlp) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->soynlp) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->soynlp) (1.1.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install soynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: customized_konlpy in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0.64)\n",
      "Requirement already satisfied: konlpy>=0.4.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from customized_konlpy) (0.6.0)\n",
      "Requirement already satisfied: Jpype1>=0.6.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from customized_konlpy) (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy>=0.4.4->customized_konlpy) (1.21.5)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy>=0.4.4->customized_konlpy) (4.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install customized_konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_preprocessing_tools_for_korean_text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url 홈페이지 BeautifulSoup을이용해서 소스에 있는 내용 부르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "판다. /픽사베이통통한 몸집과 어울리지 않게 대나무를 주식으로 하는 판다. 이런 판다의 독특한 식성이 최소 600만년 전부터 이어졌을 가능성이 있다는 연구 결과가 나왔다.1일(현지 시각) CNN 등 외신에 따르면 미국 로스앤젤레스 자연사 박물관의 왕 샤오밍 박사 연구팀은 최근 약 600만년 전 자이언트 판다 조상인 아일루락토스(Ailurarctos) 화석을 분석한 결과, 대나무를 잡는 데 쓰이는 ‘가짜 엄지’가 존재했다고 밝혔다.이 화석은 중국 남부 윈난성 자오퉁시의 슈이탕바 지역에서 발굴됐다. 약 600만년 전 살았던 고대 판다 아일루락토스의 것이다. 눈여겨볼 것은 손목 부위에서 발견된 돌출 뼈다. 연구팀은 바로 이 뼈가 자이언트 판다가 가진 여섯 번째 손가락 일명 ‘가짜 엄지’라고 말했다.판다의 가짜 엄지. /뉴시스판다의 가짜 엄지는 대나무를 보다 쉽게 잡을 수 있도록 하는 데 쓰인다. 판다가 초식동물로 진화하는 데 중추적인 역할을 했을 것으로 전문가들은 보고 있다. 그동안 이같은 진화적 적응은 약 15만년 전인 비교적 최근 이뤄진 것으로 여겨져 왔는데, 이번 연구가 무려 600만년을 거슬러 올라간다는 것을 증명해낸 셈이다.화석에서 발견된 가짜 엄지는 현대 판다의 것보다 더 긴 길이의 직선 모양을 하고 있었다. 연구팀은 “가짜 엄지는 대나무를 잡고 뜯어먹을 때는 물론 다음 먹이를 찾아 걸어갈 때 몸무게를 지탱하는 용도로도 쓰이는데, 이 과정에서 긴 뼈가 짧은 갈고리형으로 진화하게 된 것”이라고 분석했다.왕 박사는 “대나무를 먹기 좋게 쪼개기 위해 줄기를 단단히 붙잡는 것은 많은 양의 대나무를 먹는 데 가장 중요한 적응”이라며 “육식성 조상에서 진화해 대나무만 먹는 종으로 바뀐 판다는 많은 장애를 넘어야 했을 것이고 가짜 엄지는 그중 가장 놀라운 진화”라고 설명했다.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "판다. / 픽사베이통통한 몸집과 어울리지 않게 대나무를 주식으로 하는 판다. 이런 판다의 독특한 식성이 최소 600만년 전부터 이어졌을 가능성이 있다는 연구 결과가 나왔다.1일(현지시각) CNN 등 외신에 따르면 미국 로스앤젤레스 자연사박물관의 왕샤오밍 박사 연구팀은 최근 약 600만년 전자이언트 판다 조상인 아일루락토스(A ilurarctos) 화석을 분석한 결과, 대나무를 잡는 데 쓰이는 ‘가짜 엄지’가 존재했다고 밝혔다.이 화석은 중국 남부 윈 난성자오퉁시의 슈이 탕바지역에서 발굴됐다. 약 600만년 전 살았던 고대 판다 아일루락토스의 것이다. 눈여겨볼 것은 손목 부위에서 발견된 돌출뼈다. 연구팀은 바로 이 뼈가 자이언트 판다가 가진 여섯 번째 손가락 일명 ‘가짜 엄지’라고 말했다. 판다의 가짜 엄지. / 뉴시스판다의 가짜 엄지는 대나무를 보다 쉽게 잡을 수 있도록 하는데 쓰인다. 판다가 초식동물로 진화하는 데 중추적인 역할을 했을 것으로 전문가들은 보고 있다. 그동안 이 같은 진화적 적응은 약 15만년 전 인 비교적 최근 이뤄진 것으로 여겨져 왔는데, 이번 연구가 무려 600만년을 거슬러 올라간다는 것을 증명해낸 셈이다. 화석에서 발견된 가짜 엄지는 현대판다의 것보다 더 긴 길이의 직선 모양을 하고 있었다. 연구팀은 “가짜 엄지는 대나무를 잡고 뜯어먹을 때는 물론 다음 먹이를 찾아 걸어갈 때 몸무게를 지탱하는 용도로도 쓰이는데, 이 과정에서 긴 뼈가 짧은 갈고리형으로 진화하게 된 것”이라고 분석했다. 왕 박사는 “대나무를 먹기 좋게 쪼개기 위해 줄기를 단단히 붙잡는 것은 많은 양의 대나무를 먹는 데 가장 중요한 적응”이라며 “육식성 조상에서 진화해 대나무만 먹는 종으로 바뀐 판다는 많은 장애를 넘어야 했을 것이고 가짜 엄지는 그 중 가장 놀라운 진화”라고 설명했다.\n"
     ]
    }
   ],
   "source": [
    "headers = {\"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36\"}\n",
    "response_0 = requests.get(chosun_eilbo_database[\"url\"][0], headers=headers)\n",
    "soup_0 = BeautifulSoup(response_0.text, 'html.parser')\n",
    "content_0_data = soup_0.find('div', {\"id\" : \"dic_area\"}).get_text()\n",
    "content_0_data = content_0_data.replace('\\n','').replace('\\t','')\n",
    "print(content_0_data)\n",
    "new_content_0_data = content_0_data.replace(\" \", '')\n",
    "\n",
    "kospacing_new_content_0_data = spacing(new_content_0_data) \n",
    "print(kospacing_new_content_0_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['판다', '.', '/', '픽사', '베이', '통통', '한', '몸집', '과', '어울', '리지', '않게', '대나무', '를', '주식', '으로', '하는', '판다', '.', '이런', '판다', '의', '독특', '한', '식성', '이', '최소', '600', '만년', '전부', '터', '이어졌을', '가능성', '이', '있다는', '연구', '결과', '가', '나왔다', '.', '1일', '(', '현지', '시각', ')', 'CNN', '등', '외신', '에', '따르면', '미국', '로스앤젤레스', '자연사', '박물관', '의', '왕샤오밍', '박사', '연구', '팀', '은', '최근', '약', '600', '만년', '전', '자이언트', '판다', '조상', '인', '아', '일루', '락토스', '(', 'A', 'ilurarctos', ')', '화석', '을', '분석', '한', '결과', ',', '대나무', '를', '잡는', '데', '쓰이는', '‘', '가짜', '엄지', '’', '가', '존재', '했다고', '밝혔다', '.', '이', '화석', '은', '중국', '남부', '윈', '난', '성', '자오퉁시', '의', '슈이', '탕바', '지역', '에서', '발굴', '됐다', '.', '약', '600', '만년', '전', '살았던', '고대', '판다', '아', '일루', '락토스', '의', '것', '이다', '.', '눈', '여겨', '볼', '것', '은', '손목', '부위', '에서', '발견', '된', '돌출', '뼈', '다', '.', '연구', '팀', '은', '바로', '이', '뼈', '가', '자이언트', '판다', '가', '가진', '여섯', '번째', '손가락', '일명', '‘', '가짜', '엄지', '’', '라고', '말', '했다', '.', '판다', '의', '가짜', '엄지', '.', '/', '뉴시스', '판다', '의', '가짜', '엄지', '는', '대나무', '를', '보다', '쉽게', '잡', '을', '수', '있', '도록', '하는데', '쓰인다', '.', '판다', '가', '초식동물', '로', '진화', '하는', '데', '중', '추적', '인', '역할', '을', '했을', '것', '으로', '전문가', '들은', '보고', '있다', '.', '그동안', '이', '같은', '진화', '적', '적응', '은', '약', '15', '만년', '전', '인', '비교', '적', '최근', '이뤄진', '것', '으로', '여겨져', '왔는데', ',', '이번', '연구', '가', '무려', '600', '만년', '을', '거슬러', '올라', '간다', '는', '것', '을', '증명', '해', '낸', '셈', '이다', '.', '화석', '에서', '발견', '된', '가짜', '엄지', '는', '현대', '판다', '의', '것', '보다', '더', '긴', '길이', '의', '직선', '모양', '을', '하고', '있었다', '.', '연구', '팀', '은', '“', '가짜', '엄지', '는', '대나무', '를', '잡고', '뜯어', '먹을', '때', '는', '물론', '다음', '먹이', '를', '찾아', '걸어갈', '때', '몸무게', '를', '지탱', '하는', '용도', '로', '도', '쓰이는데', ',', '이', '과정', '에서', '긴', '뼈', '가', '짧은', '갈고리', '형', '으로', '진화', '하게', '된', '것', '”', '이라고', '분석', '했다', '.', '왕', '박사', '는', '“', '대나무', '를', '먹기', '좋게', '쪼개기', '위해', '줄기', '를', '단단히', '붙잡는', '것', '은', '많은', '양', '의', '대나무', '를', '먹는', '데', '가장', '중요', '한', '적응', '”', '이', '라며', '“', '육식성', '조상', '에서', '진화', '해', '대나무', '만', '먹는', '종', '으로', '바뀐', '판다', '는', '많은', '장애', '를', '넘어야', '했을', '것', '이고', '가짜', '엄지', '는', '그', '중', '가장', '놀라운', '진화', '”', '라고', '설명', '했다', '.']\n"
     ]
    }
   ],
   "source": [
    "print(twitter.morphs(kospacing_new_content_0_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_data = twitter.morphs(content_0_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표제어 제거하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어 추출 후 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n",
      "die\n",
      "watch\n",
      "have\n",
      "어간 추출 전 : ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n",
      "어간 추출 후 : ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n",
      "어간 추출 전 : ['formalize', 'allowance', 'electricical']\n",
      "어간 추출 후 : ['formal', 'allow', 'electric']\n",
      "어간 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "포터 스테머의 어간 추출 후: ['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n",
      "랭커스터 스테머의 어간 추출 후: ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
     ]
    }
   ],
   "source": [
    "from stemming_lemmatization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for word in words_data:\n",
    "#     print(lemmatizer.lemmatize(word))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스 내용항목 중 한국어 불용어 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "불용어 10개 출력 : ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n",
      "불용어 제거 전 : ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
      "불용어 제거 후 : ['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
      "불용어 제거 전 : ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
      "불용어 제거 후 : ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from remove_stopwords import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 전 : ['판다', '.', '/', '픽사', '베이', '통통', '한', '몸집', '과', '어울', '리지', '않게', '대나무', '를', '주식', '으로', '하는', '판다', '.', '이런', '판다', '의', '독특', '한', '식성', '이', '최소', '600', '만년', '전부', '터', '이어졌을', '가능성', '이', '있다는', '연구', '결과', '가', '나왔다', '.', '1일', '(', '현지', '시각', ')', 'CNN', '등', '외신', '에', '따르면', '미국', '로스앤젤레스', '자연사', '박물관', '의', '왕', '샤오밍', '박사', '연구', '팀', '은', '최근', '약', '600', '만년', '전', '자이언트', '판다', '조상', '인', '아', '일루', '락토스', '(', 'Ailurarctos', ')', '화석', '을', '분석', '한', '결과', ',', '대나무', '를', '잡는', '데', '쓰이는', '‘', '가짜', '엄지', '’', '가', '존재', '했다고', '밝혔다', '.', '이', '화석', '은', '중국', '남부', '윈난성', '자오퉁시', '의', '슈이탕바', '지역', '에서', '발굴', '됐다', '.', '약', '600', '만년', '전', '살았던', '고대', '판다', '아', '일루', '락토스', '의', '것', '이다', '.', '눈', '여겨', '볼', '것', '은', '손목', '부위', '에서', '발견', '된', '돌출', '뼈', '다', '.', '연구', '팀', '은', '바로', '이', '뼈', '가', '자이언트', '판다', '가', '가진', '여섯', '번째', '손가락', '일명', '‘', '가짜', '엄지', '’', '라고', '말', '했다', '.', '판다', '의', '가짜', '엄지', '.', '/', '뉴시스', '판다', '의', '가짜', '엄지', '는', '대나무', '를', '보다', '쉽게', '잡', '을', '수', '있', '도록', '하는', '데', '쓰인다', '.', '판다', '가', '초식동물', '로', '진화', '하는', '데', '중', '추적', '인', '역할', '을', '했을', '것', '으로', '전문가', '들은', '보고', '있다', '.', '그동안', '이', '같은', '진화', '적', '적응', '은', '약', '15', '만년', '전인', '비교', '적', '최근', '이뤄진', '것', '으로', '여겨져', '왔는데', ',', '이번', '연구', '가', '무려', '600', '만년', '을', '거슬러', '올라', '간다', '는', '것', '을', '증명', '해', '낸', '셈', '이다', '.', '화석', '에서', '발견', '된', '가짜', '엄지', '는', '현대', '판다', '의', '것', '보다', '더', '긴', '길이', '의', '직선', '모양', '을', '하고', '있었다', '.', '연구', '팀', '은', '“', '가짜', '엄지', '는', '대나무', '를', '잡고', '뜯어', '먹을', '때', '는', '물론', '다음', '먹이', '를', '찾아', '걸어갈', '때', '몸무게', '를', '지탱', '하는', '용도', '로', '도', '쓰이는데', ',', '이', '과정', '에서', '긴', '뼈', '가', '짧은', '갈고리', '형', '으로', '진화', '하게', '된', '것', '”', '이라고', '분석', '했다', '.', '왕', '박사', '는', '“', '대나무', '를', '먹기', '좋게', '쪼개기', '위해', '줄기', '를', '단단히', '붙잡는', '것', '은', '많은', '양', '의', '대나무', '를', '먹는', '데', '가장', '중요', '한', '적응', '”', '이', '라며', '“', '육식성', '조상', '에서', '진화', '해', '대나무', '만', '먹는', '종', '으로', '바뀐', '판다', '는', '많은', '장애', '를', '넘어야', '했을', '것', '이고', '가짜', '엄지', '는', '그중', '가장', '놀라운', '진화', '”', '라고', '설명', '했다', '.']\n",
      "\n",
      "불용어 제거 후 : ['판다', '.', '/', '픽사', '베이', '통통', '한', '몸집', '어울', '리지', '않게', '대나무', '주식', '하는', '판다', '.', '판다', '독특', '한', '식성', '최소', '600', '만년', '터', '이어졌을', '가능성', '있다는', '연구', '결과', '나왔다', '.', '1일', '(', '현지', ')', 'CNN', '외신', '따르면', '미국', '로스앤젤레스', '자연사', '박물관', '왕', '샤오밍', '박사', '연구', '팀', '은', '최근', '약', '600', '만년', '전', '자이언트', '판다', '조상', '인', '일루', '락토스', '(', 'Ailurarctos', ')', '화석', '분석', '한', '결과', ',', '대나무', '잡는', '데', '쓰이는', '‘', '가짜', '엄지', '’', '존재', '했다고', '밝혔다', '.', '화석', '은', '중국', '남부', '윈난성', '자오퉁시', '슈이탕바', '지역', '발굴', '됐다', '.', '약', '600', '만년', '전', '살았던', '고대', '판다', '일루', '락토스', '이다', '.', '눈', '여겨', '볼', '은', '손목', '부위', '발견', '된', '돌출', '뼈', '다', '.', '연구', '팀', '은', '뼈', '자이언트', '판다', '가진', '번째', '손가락', '일명', '‘', '가짜', '엄지', '’', '라고', '말', '했다', '.', '판다', '가짜', '엄지', '.', '/', '뉴시스', '판다', '가짜', '엄지', '는', '대나무', '보다', '쉽게', '잡', '수', '있', '도록', '하는', '데', '쓰인다', '.', '판다', '초식동물', '진화', '하는', '데', '중', '추적', '인', '역할', '했을', '전문가', '들은', '보고', '.', '그동안', '같은', '진화', '적', '적응', '은', '약', '15', '만년', '전인', '비교', '적', '최근', '이뤄진', '여겨져', '왔는데', ',', '연구', '무려', '600', '만년', '거슬러', '올라', '간다', '는', '증명', '해', '낸', '셈', '이다', '.', '화석', '발견', '된', '가짜', '엄지', '는', '현대', '판다', '보다', '더', '긴', '길이', '직선', '모양', '하고', '있었다', '.', '연구', '팀', '은', '“', '가짜', '엄지', '는', '대나무', '잡고', '뜯어', '먹을', '는', '먹이', '찾아', '걸어갈', '몸무게', '지탱', '하는', '용도', '도', '쓰이는데', ',', '과정', '긴', '뼈', '짧은', '갈고리', '형', '진화', '하게', '된', '”', '이라고', '분석', '했다', '.', '왕', '박사', '는', '“', '대나무', '먹기', '좋게', '쪼개기', '위해', '줄기', '단단히', '붙잡는', '은', '많은', '양', '대나무', '먹는', '데', '가장', '중요', '한', '적응', '”', '라며', '“', '육식성', '조상', '진화', '해', '대나무', '만', '먹는', '종', '바뀐', '판다', '는', '많은', '장애', '넘어야', '했을', '이고', '가짜', '엄지', '는', '그중', '가장', '놀라운', '진화', '”', '라고', '설명', '했다', '.']\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:\\\\Users\\\\user\\\\Documents\\\\github\\\\bigdata_thunder\\\\bigdata2\\\\korean_stopwords.txt\", \"r\", encoding=\"UTF-8\") as stopwords:\n",
    "    stopwords_list = stopwords.read().split('\\n')\n",
    "print('불용어 제거 전 :',words_data) \n",
    "print()\n",
    "print('불용어 제거 후 :',korean_change_no_stop_words(words_data, stopwords_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "판다./픽사베이통통한몸집어울리지않게대나무주식하는판다.판다독특한식성최소600만년터이어졌을가능성있다는연구결과나왔다.1일(현지)CNN외신따르면미국로스앤젤레스자연사박물관왕샤오밍박사연구팀은최근약600만년전자이언트판다조상인일루락토스(Ailurarctos)화석분석한결과,대나무잡는데쓰이는‘가짜엄지’존재했다고밝혔다.화석은중국남부윈난성자오퉁시슈이탕바지역발굴됐다.약600만년전살았던고대판다일루락토스이다.눈여겨볼은손목부위발견된돌출뼈다.연구팀은뼈자이언트판다가진번째손가락일명‘가짜엄지’라고말했다.판다가짜엄지./뉴시스판다가짜엄지는대나무보다쉽게잡수있도록하는데쓰인다.판다초식동물진화하는데중추적인역할했을전문가들은보고.그동안같은진화적적응은약15만년전인비교적최근이뤄진여겨져왔는데,연구무려600만년거슬러올라간다는증명해낸셈이다.화석발견된가짜엄지는현대판다보다더긴길이직선모양하고있었다.연구팀은“가짜엄지는대나무잡고뜯어먹을는먹이찾아걸어갈몸무게지탱하는용도도쓰이는데,과정긴뼈짧은갈고리형진화하게된”이라고분석했다.왕박사는“대나무먹기좋게쪼개기위해줄기단단히붙잡는은많은양대나무먹는데가장중요한적응”라며“육식성조상진화해대나무만먹는종바뀐판다는많은장애넘어야했을이고가짜엄지는그중가장놀라운진화”라고설명했다.\n"
     ]
    }
   ],
   "source": [
    "new_content_1 ='' \n",
    "for i in korean_change_no_stop_words(words_data, stopwords_list):\n",
    "    new_content_1 += i\n",
    "print(new_content_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 텍스트 정규화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular expression   A regular expression  regex or regexp     sometimes called a rational expression        is  in theoretical computer science and formal language theory  a sequence of characters that define a search pattern \n",
      "['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n",
      "[\"Don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name,', 'Mr.', \"Jone's\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
     ]
    }
   ],
   "source": [
    "from regular_expression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['판다.', '픽사베이통통한몸집어울리지않게대나무주식하는판다.판다독특한식성최소', '만년터이어졌을가능성있다는연구결과나왔다.', '일', '현지', '외신따르면미국로스앤젤레스자연사박물관왕샤오밍박사연구팀은최근약', '만년전자이언트판다조상인일루락토스', '화석분석한결과,대나무잡는데쓰이는‘가짜엄지’존재했다고밝혔다.화석은중국남부윈난성자오퉁시슈이탕바지역발굴됐다.약', '만년전살았던고대판다일루락토스이다.눈여겨볼은손목부위발견된돌출뼈다.연구팀은뼈자이언트판다가진번째손가락일명‘가짜엄지’라고말했다.판다가짜엄지.', '뉴시스판다가짜엄지는대나무보다쉽게잡수있도록하는데쓰인다.판다초식동물진화하는데중추적인역할했을전문가들은보고.그동안같은진화적적응은약', '만년전인비교적최근이뤄진여겨져왔는데,연구무려', '만년거슬러올라간다는증명해낸셈이다.화석발견된가짜엄지는현대판다보다더긴길이직선모양하고있었다.연구팀은“가짜엄지는대나무잡고뜯어먹을는먹이찾아걸어갈몸무게지탱하는용도도쓰이는데,과정긴뼈짧은갈고리형진화하게된”이라고분석했다.왕박사는“대나무먹기좋게쪼개기위해줄기단단히붙잡는은많은양대나무먹는데가장중요한적응”라며“육식성조상진화해대나무만먹는종바뀐판다는많은장애넘어야했을이고가짜엄지는그중가장놀라운진화”라고설명했다.']\n"
     ]
    }
   ],
   "source": [
    "tokenizer3_content_1 = RegexpTokenizer('[A-Za-z0-9ㄱ-ㅎ/()]+', gaps=True)\n",
    "# tokenizer3_content_2 = RegexpTokenizer('')\n",
    "print(tokenizer3_content_1.tokenize(new_content_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "판다.픽사베이통통한몸집어울리지않게대나무주식하는판다.판다독특한식성최소만년터이어졌을가능성있다는연구결과나왔다.일현지외신따르면미국로스앤젤레스자연사박물관왕샤오밍박사연구팀은최근약만년전자이언트판다조상인일루락토스화석분석한결과,대나무잡는데쓰이는‘가짜엄지’존재했다고밝혔다.화석은중국남부윈난성자오퉁시슈이탕바지역발굴됐다.약만년전살았던고대판다일루락토스이다.눈여겨볼은손목부위발견된돌출뼈다.연구팀은뼈자이언트판다가진번째손가락일명‘가짜엄지’라고말했다.판다가짜엄지.뉴시스판다가짜엄지는대나무보다쉽게잡수있도록하는데쓰인다.판다초식동물진화하는데중추적인역할했을전문가들은보고.그동안같은진화적적응은약만년전인비교적최근이뤄진여겨져왔는데,연구무려만년거슬러올라간다는증명해낸셈이다.화석발견된가짜엄지는현대판다보다더긴길이직선모양하고있었다.연구팀은“가짜엄지는대나무잡고뜯어먹을는먹이찾아걸어갈몸무게지탱하는용도도쓰이는데,과정긴뼈짧은갈고리형진화하게된”이라고분석했다.왕박사는“대나무먹기좋게쪼개기위해줄기단단히붙잡는은많은양대나무먹는데가장중요한적응”라며“육식성조상진화해대나무만먹는종바뀐판다는많은장애넘어야했을이고가짜엄지는그중가장놀라운진화”라고설명했다.\n"
     ]
    }
   ],
   "source": [
    "regular_expression_sentence = ''\n",
    "for expression in tokenizer3_content_1.tokenize(new_content_1):\n",
    "    regular_expression_sentence += expression\n",
    "print(regular_expression_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n",
      "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
      "{'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n",
      "8\n",
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n",
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n",
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n",
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'OOV': 6}\n",
      "[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n",
      "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
      "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n",
      "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n",
      "8\n",
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n",
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n",
      "8\n",
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n",
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n",
      "value : a, index: 0\n",
      "value : b, index: 1\n",
      "value : c, index: 2\n",
      "value : d, index: 3\n",
      "value : e, index: 4\n",
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n",
      "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n",
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n",
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n",
      "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n",
      "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n",
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n",
      "OrderedDict([('barber', 8), ('person', 3), ('huge', 5), ('secret', 6), ('kept', 4)])\n",
      "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n",
      "단어 OOV의 인덱스 : 1\n",
      "[[2, 6], [2, 1, 6], [2, 4, 6], [1, 3], [3, 5, 4, 3], [4, 3], [2, 5, 1], [2, 5, 1], [2, 5, 3], [1, 1, 4, 3, 1, 2, 1], [2, 1, 4, 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from integer_encoding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['barber', 'went', 'huge', 'mountain', '대나무', '가능성', '로스앤젤레스', '자연사', '박물관', '왕샤오밍', '자이언트판다', '락토스', '대나무', '윈난성', '자오퉁시', '슈이탕바', '락토스', '자이언트판다', '손가락', '뉴시스', '대나무', '초식동물', '전문가', '그동안', '년거슬러올', '대나무', '몸무게', '갈고리', '대나무', '대나무', '육식성', '대나무']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab = {}\n",
    "preprocessed_sentences = []\n",
    "\n",
    "for sentence in sent_tokenize(regular_expression_sentence):\n",
    "    # 단어 토큰화\n",
    "    tokenized_sentence = twitter.nouns(sentence)\n",
    "\n",
    "    for word in tokenized_sentence: \n",
    "        if len(word) > 2: \n",
    "            result.append(word)\n",
    "            if word not in vocab:\n",
    "                vocab[word] = 0 \n",
    "            vocab[word] += 1\n",
    "    preprocessed_sentences.append(result) \n",
    "print(preprocessed_sentences)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'대나무': 7, '가능성': 1, '로스앤젤레스': 1, '자연사': 1, '박물관': 1, '왕샤오밍': 1, '자이언트판다': 2, '락토스': 2, '윈난성': 1, '자오퉁시': 1, '슈이탕바': 1, '손가락': 1, '뉴시스': 1, '초식동물': 1, '전문가': 1, '그동안': 1, '년거슬러올': 1, '몸무게': 1, '갈고리': 1, '육식성': 1}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barber', 'went', 'huge', 'mountain', '대나무', '가능성', '로스앤젤레스', '자연사', '박물관', '왕샤오밍', '자이언트판다', '락토스', '대나무', '윈난성', '자오퉁시', '슈이탕바', '락토스', '자이언트판다', '손가락', '뉴시스', '대나무', '초식동물', '전문가', '그동안', '년거슬러올', '대나무', '몸무게', '갈고리', '대나무', '대나무', '육식성', '대나무']\n"
     ]
    }
   ],
   "source": [
    "all_words_list = sum(preprocessed_sentences, [])\n",
    "print(all_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'대나무': 7, '자이언트판다': 2, '락토스': 2, 'barber': 1, 'went': 1, 'huge': 1, 'mountain': 1, '가능성': 1, '로스앤젤레스': 1, '자연사': 1, '박물관': 1, '왕샤오밍': 1, '윈난성': 1, '자오퉁시': 1, '슈이탕바': 1, '손가락': 1, '뉴시스': 1, '초식동물': 1, '전문가': 1, '그동안': 1, '년거슬러올': 1, '몸무게': 1, '갈고리': 1, '육식성': 1})\n"
     ]
    }
   ],
   "source": [
    "vocab = Counter(all_words_list)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(vocab[\"판다\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('대나무', 7), ('자이언트판다', 2), ('락토스', 2), ('barber', 1), ('went', 1), ('huge', 1), ('mountain', 1), ('가능성', 1), ('로스앤젤레스', 1), ('자연사', 1)]\n",
      "{'대나무': 1, '자이언트판다': 2, '락토스': 3, 'barber': 4, 'went': 5, 'huge': 6, 'mountain': 7, '가능성': 8, '로스앤젤레스': 9, '자연사': 10}\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10\n",
    "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
    "print(vocab)\n",
    "\n",
    "word_to_index = {}\n",
    "i = 0\n",
    "for (word, frequency) in vocab :\n",
    "    i = i + 1\n",
    "    word_to_index[word] = i\n",
    "    \n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'대나무': 1, '자이언트판다': 2, '락토스': 3, 'barber': 4, 'went': 5, 'huge': 6, 'mountain': 7, '가능성': 8, '로스앤젤레스': 9, '자연사': 10, '박물관': 11, '왕샤오밍': 12, '윈난성': 13, '자오퉁시': 14, '슈이탕바': 15, '손가락': 16, '뉴시스': 17, '초식동물': 18, '전문가': 19, '그동안': 20, '년거슬러올': 21, '몸무게': 22, '갈고리': 23, '육식성': 24}\n",
      "\n",
      "OrderedDict([('barber', 1), ('went', 1), ('huge', 1), ('mountain', 1), ('대나무', 7), ('가능성', 1), ('로스앤젤레스', 1), ('자연사', 1), ('박물관', 1), ('왕샤오밍', 1), ('자이언트판다', 2), ('락토스', 2), ('윈난성', 1), ('자오퉁시', 1), ('슈이탕바', 1), ('손가락', 1), ('뉴시스', 1), ('초식동물', 1), ('전문가', 1), ('그동안', 1), ('년거슬러올', 1), ('몸무게', 1), ('갈고리', 1), ('육식성', 1)])\n",
      "\n",
      "[[4, 5, 6, 7, 1, 8, 9, 10, 11, 12, 2, 3, 1, 13, 14, 15, 3, 2, 16, 17, 1, 18, 19, 20, 21, 1, 22, 23, 1, 1, 24, 1]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)\n",
    "print(tokenizer.word_index)\n",
    "print()\n",
    "print(tokenizer.word_counts)\n",
    "print()\n",
    "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'대나무': 1, '자이언트판다': 2, '락토스': 3, 'barber': 4, 'went': 5, 'huge': 6, 'mountain': 7, '가능성': 8, '로스앤젤레스': 9, '자연사': 10, '박물관': 11, '왕샤오밍': 12, '윈난성': 13, '자오퉁시': 14, '슈이탕바': 15, '손가락': 16, '뉴시스': 17, '초식동물': 18, '전문가': 19, '그동안': 20, '년거슬러올': 21, '몸무게': 22, '갈고리': 23, '육식성': 24}\n",
      "\n",
      "OrderedDict([('barber', 1), ('went', 1), ('huge', 1), ('mountain', 1), ('대나무', 7), ('가능성', 1), ('로스앤젤레스', 1), ('자연사', 1), ('박물관', 1), ('왕샤오밍', 1), ('자이언트판다', 2), ('락토스', 2), ('윈난성', 1), ('자오퉁시', 1), ('슈이탕바', 1), ('손가락', 1), ('뉴시스', 1), ('초식동물', 1), ('전문가', 1), ('그동안', 1), ('년거슬러올', 1), ('몸무게', 1), ('갈고리', 1), ('육식성', 1)])\n",
      "\n",
      "[[4, 5, 6, 7, 1, 8, 9, 10, 2, 3, 1, 3, 2, 1, 1, 1, 1, 1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10\n",
    "tokenizer = Tokenizer(num_words = vocab_size + 1) # 상위 10개 단어만 사용\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print()\n",
    "print(tokenizer.word_counts)\n",
    "print()\n",
    "print(tokenizer.texts_to_sequences(preprocessed_sentences))\n",
    "print()\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'대나무': 1, '자이언트판다': 2, '락토스': 3, 'barber': 4, 'went': 5, 'huge': 6, 'mountain': 7, '가능성': 8, '로스앤젤레스': 9, '자연사': 10}\n",
      "OrderedDict([('barber', 1), ('went', 1), ('huge', 1), ('mountain', 1), ('대나무', 7), ('가능성', 1), ('로스앤젤레스', 1), ('자연사', 1), ('자이언트판다', 2), ('락토스', 2)])\n",
      "[[4, 5, 6, 7, 1, 8, 9, 10, 2, 3, 1, 3, 2, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "words_frequency = [word for word, index in tokenizer.word_index.items() if index >= vocab_size + 1] # 인덱스가 5 초과인 단어 제거\n",
    "for word in words_frequency:\n",
    "    del tokenizer.word_index[word] # 해당 단어에 대한 인덱스 정보를 삭제\n",
    "    del tokenizer.word_counts[word] # 해당 단어에 대한 카운트 정보를 삭제\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(tokenizer.word_counts)\n",
    "print(tokenizer.texts_to_sequences(preprocessed_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.10.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '자연어', '처리', '를', '배운다']\n",
      "단어 집합 : {'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n",
      "단어 집합 : {'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n",
      "[2, 5, 1, 6, 3, 7]\n",
      "[2, 5, 1, 6, 3, 7]\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from one_encoding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['판다', '는', '언제', '부터', '대나무', '만', '먹었을까', '?', '600', '만년', '전', '화석', '봤', '더니', '…']\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "tokens = twitter.morphs(chosun_eilbo_database['title'][0])\n",
    "print(tokens)\n",
    "word_to_index = {word : index for index, word in enumerate(tokens)}\n",
    "for i in tokens:\n",
    "    print(one_hot_encoding(i, word_to_index=word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n",
      "7\n",
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "from padding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "# fit_on_texts()안에 코퍼스를 입력으로 하면 빈도수를 기준으로 단어 집합을 생성.\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  1  5]\n",
      " [ 0  0  0  0  1  8  5]\n",
      " [ 0  0  0  0  1  3  5]\n",
      " [ 0  0  0  0  0  9  2]\n",
      " [ 0  0  0  2  4  3  2]\n",
      " [ 0  0  0  0  0  3  2]\n",
      " [ 0  0  0  0  1  4  6]\n",
      " [ 0  0  0  0  1  4  6]\n",
      " [ 0  0  0  0  1  4  2]\n",
      " [ 7  7  3  2 10  1 11]\n",
      " [ 0  0  0  1 12  3 13]]\n"
     ]
    }
   ],
   "source": [
    "padded_1 = pad_sequences(encoded)\n",
    "print(padded_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0,  0,  0],\n",
       "       [ 3,  2,  0,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13,  0,  0,  0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_2 = pad_sequences(encoded, padding='post')\n",
    "padded_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  5  0  0  0]\n",
      " [ 1  8  5  0  0]\n",
      " [ 1  3  5  0  0]\n",
      " [ 9  2  0  0  0]\n",
      " [ 2  4  3  2  0]\n",
      " [ 3  2  0  0  0]\n",
      " [ 1  4  6  0  0]\n",
      " [ 1  4  6  0  0]\n",
      " [ 1  4  2  0  0]\n",
      " [ 3  2 10  1 11]\n",
      " [ 1 12  3 13  0]]\n",
      "\n",
      "[[ 1  5  0  0  0  0  0]\n",
      " [ 1  8  5  0  0  0  0]\n",
      " [ 1  3  5  0  0  0  0]\n",
      " [ 9  2  0  0  0  0  0]\n",
      " [ 2  4  3  2  0  0  0]\n",
      " [ 3  2  0  0  0  0  0]\n",
      " [ 1  4  6  0  0  0  0]\n",
      " [ 1  4  6  0  0  0  0]\n",
      " [ 1  4  2  0  0  0  0]\n",
      " [ 7  7  3  2 10  1 11]\n",
      " [ 1 12  3 13  0  0  0]]\n",
      "\n",
      "[[ 1  5  0  0  0]\n",
      " [ 1  8  5  0  0]\n",
      " [ 1  3  5  0  0]\n",
      " [ 9  2  0  0  0]\n",
      " [ 2  4  3  2  0]\n",
      " [ 3  2  0  0  0]\n",
      " [ 1  4  6  0  0]\n",
      " [ 1  4  6  0  0]\n",
      " [ 1  4  2  0  0]\n",
      " [ 7  7  3  2 10]\n",
      " [ 1 12  3 13  0]]\n",
      "\n",
      "14\n",
      "\n",
      "[[ 1  5 14 14 14 14 14]\n",
      " [ 1  8  5 14 14 14 14]\n",
      " [ 1  3  5 14 14 14 14]\n",
      " [ 9  2 14 14 14 14 14]\n",
      " [ 2  4  3  2 14 14 14]\n",
      " [ 3  2 14 14 14 14 14]\n",
      " [ 1  4  6 14 14 14 14]\n",
      " [ 1  4  6 14 14 14 14]\n",
      " [ 1  4  2 14 14 14 14]\n",
      " [ 7  7  3  2 10  1 11]\n",
      " [ 1 12  3 13 14 14 14]]\n"
     ]
    }
   ],
   "source": [
    "padded_3 = pad_sequences(encoded, padding='post', maxlen=5)\n",
    "print(padded_3)\n",
    "print()\n",
    "padded_4 = pad_sequences(encoded, padding='post', truncating='post')\n",
    "print(padded_4)\n",
    "print()\n",
    "padded_5 = pad_sequences(encoded, padding='post', truncating='post', maxlen=5)\n",
    "print(padded_5)\n",
    "print()\n",
    "# 단어 집합의 크기보다 1 큰 숫자를 사용\n",
    "last_value = len(tokenizer.word_index) + 1\n",
    "print(last_value)\n",
    "print()\n",
    "padded_6 = pad_sequences(encoded, padding='post', value=last_value)\n",
    "print(padded_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF를 이용하여 벡터화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag_of_words 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bag_of_words import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'판다.픽사 베이통통한 몸집 어울리지 않게 대나무 주식하는 판다. 판다독특한 식성 최소 만년 터이어졌을 가능성 있다는 연구 결과 나왔다. 일 현지 외신 따르면 미국 로스앤젤레스 자연사박물관 왕샤오밍 박사 연구팀은 최근 약 만년 전자이언트 판다 조상인 일루락토스 화 석 분석한 결과, 대나무 잡는데 쓰이는 ‘가짜 엄지’ 존재했다고 밝혔다. 화석은 중국 남부 윈난성 자오퉁시 슈이 탕바지역 발굴됐다.약 만년 전 살았던 고대 판다일루락토스이다. 눈여겨볼은 손목 부위 발견된 돌출뼈다. 연구팀은 뼈 자이언트 판다가 진번째 손가락 일명 ‘가짜 엄지’라고 말했다. 판다가짜 엄지.뉴시스판다가짜 엄지는 대나무보다 쉽게 잡수 있도록 하는 데 쓰인다. 판다초식 동물 진화하는데 중추적인 역할했을 전문가들은 보고. 그동안 같은 진화적 적응은 약 만년 전 인 비교적 최근 이뤄진 여겨져 왔는데, 연구 무려 만년 거슬러 올라간다는 증명해낸 셈이다. 화석 발견된 가짜 엄지는 현대판다보다 더 긴 길이 직선 모양하고 있었다.연구팀은 “가짜 엄지는 대나무 잡고 뜯어먹을는 먹이 찾아 걸어갈 몸무게 지탱하는 용도도 쓰이는데, 과정 긴 뼈 짧은 갈고리형 진화하게 된”이라고 분석했다. 왕 박사는 “대나무 먹기 좋게 쪼개기 위해 줄기 단단히 붙잡는 은 많은 양대나무 먹는데 가장 중요한 적응”라며 “육식성 조상 진화해대나무만 먹는 종 바뀐 판다는 많은 장애 넘어야 했을 이고 가짜 엄지는 그 중 가장 놀라운 진화”라고 설명했다.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiwi = Kiwi()\n",
    "spacing = Spacing()\n",
    "kospacing_sent = spacing(regular_expression_sentence) \n",
    "\n",
    "kospacing_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'판다': 0, '픽사': 1, '베이': 2, '통통한': 3, '몸집': 4, '어울리지': 5, '않게': 6, '대나무': 7, '주식': 8, '하는': 9, '독특한': 10, '식성': 11, '최소': 12, '만년': 13, '터': 14, '이어졌을': 15, '가능성': 16, '있다는': 17, '연구': 18, '결과': 19, '나왔다': 20, '일': 21, '현지': 22, '외신': 23, '따르면': 24, '미국': 25, '로스앤젤레스': 26, '자연사': 27, '박물관': 28, '왕샤오밍': 29, '박사': 30, '연': 31, '구': 32, '팀': 33, '은': 34, '최근': 35, '약': 36, '전': 37, '자이언트': 38, '조상': 39, '인': 40, '일루': 41, '락토스': 42, '화': 43, '석': 44, '분석': 45, '한': 46, ',': 47, '잡는데': 48, '쓰이는': 49, '‘': 50, '가짜': 51, '엄지': 52, '’': 53, '존재': 54, '했다고': 55, '밝혔다': 56, '화석': 57, '중국': 58, '남부': 59, '윈난성': 60, '자오퉁시': 61, '슈이': 62, '탕바': 63, '지역': 64, '발굴': 65, '됐다': 66, '살았던': 67, '고대': 68, '이다': 69, '눈': 70, '여겨': 71, '볼': 72, '손목': 73, '부위': 74, '발견': 75, '된': 76, '돌출': 77, '뼈': 78, '다': 79, '가': 80, '진번': 81, '째': 82, '손가락': 83, '일명': 84, '라고': 85, '말': 86, '했다': 87, '뉴시스': 88, '는': 89, '보다': 90, '쉽게': 91, '잡수': 92, '있도록': 93, '데': 94, '쓰인다': 95, '초식': 96, '동물': 97, '진화': 98, '하는데': 99, '중추': 100, '적': 101, '역할': 102, '했을': 103, '전문가': 104, '들': 105, '보고': 106, '그동안': 107, '같은': 108, '적응': 109, '비교': 110, '이뤄진': 111, '여겨져': 112, '왔는데': 113, '무려': 114, '거슬러': 115, '올라간다는': 116, '증명': 117, '해낸': 118, '셈': 119, '현': 120, '대': 121, '더': 122, '긴': 123, '길이': 124, '직선': 125, '모양': 126, '하고': 127, '있었다': 128, '“': 129, '잡고': 130, '뜯어': 131, '먹을는': 132, '먹이': 133, '찾아': 134, '걸어갈': 135, '몸무게': 136, '지탱': 137, '용도': 138, '도': 139, '쓰이는데': 140, '과정': 141, '짧은': 142, '갈고리': 143, '형': 144, '하게': 145, '”': 146, '이라고': 147, '왕': 148, '먹기': 149, '좋게': 150, '쪼개기': 151, '위해': 152, '줄기': 153, '단단히': 154, '붙잡는': 155, '많은': 156, '양대': 157, '나무': 158, '먹는데': 159, '가장': 160, '중요한': 161, '라며': 162, '육식성': 163, '해': 164, '만': 165, '먹는': 166, '종': 167, '바뀐': 168, '장애': 169, '넘어야': 170, '이고': 171, '그': 172, '중': 173, '놀라운': 174, '설명': 175}\n",
      "[11, 1, 1, 1, 1, 1, 1, 6, 1, 3, 1, 1, 1, 5, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 8, 2, 3, 3, 2, 2, 3, 2, 2, 1, 1, 2, 1, 3, 1, 1, 2, 7, 7, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 6, 2, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "vocab, bow = build_bag_of_words(kospacing_sent)\n",
    "print(vocab)\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_idf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "판다.픽사 베이통통한 몸집 어울리지 않게 대나무 주식하는 판다. 판다독특한 식성 최소 만년 터이어졌을 가능성 있다는 연구 결과 나왔다. 일 현지 외신 따르면 미국 로스앤젤레스 자연사박물관 왕샤오밍 박사 연구팀은 최근 약 만년 전자이언트 판다 조상인 일루락토스 화 석 분석한 결과, 대나무 잡는데 쓰이는 ‘가짜 엄지’ 존재했다고 밝혔다. 화석은 중국 남부 윈난성 자오퉁시 슈이 탕바지역 발굴됐다.약 만년 전 살았던 고대 판다일루락토스이다. 눈여겨볼은 손목 부위 발견된 돌출뼈다. 연구팀은 뼈 자이언트 판다가 진번째 손가락 일명 ‘가짜 엄지’라고 말했다. 판다가짜 엄지.뉴시스판다가짜 엄지는 대나무보다 쉽게 잡수 있도록 하는 데 쓰인다. 판다초식 동물 진화하는데 중추적인 역할했을 전문가들은 보고. 그동안 같은 진화적 적응은 약 만년 전 인 비교적 최근 이뤄진 여겨져 왔는데, 연구 무려 만년 거슬러 올라간다는 증명해낸 셈이다. 화석 발견된 가짜 엄지는 현대판다보다 더 긴 길이 직선 모양하고 있었다.연구팀은 “가짜 엄지는 대나무 잡고 뜯어먹을는 먹이 찾아 걸어갈 몸무게 지탱하는 용도도 쓰이는데, 과정 긴 뼈 짧은 갈고리형 진화하게 된”이라고 분석했다. 왕 박사는 “대나무 먹기 좋게 쪼개기 위해 줄기 단단히 붙잡는 은 많은 양대나무 먹는데 가장 중요한 적응”라며 “육식성 조상 진화해대나무만 먹는 종 바뀐 판다는 많은 장애 넘어야 했을 이고 가짜 엄지는 그 중 가장 놀라운 진화”라고 설명했다.\n"
     ]
    }
   ],
   "source": [
    "kospacing_sent \n",
    "print(kospacing_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'판다는 언제부터 대나무만 먹었을까? 600만년 전 화석 봤더니…'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = chosun_eilbo_database['title'][0]\n",
    "title = spacing(title)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['판다', '픽사 베이통통한 몸집 어울리지 않게 대나무 주식하는 판다', '판다독특한 식성 최소 만년 터이어졌을 가능성 있다는 연구 결과 나왔다', '일 현지 외신 따르면 미국 로스앤젤레스 자연사박물관 왕샤오밍 박사 연구팀은 최근 약 만년 전자이언트 판다 조상인 일루락토스 화 석 분석한 결과', '대나무 잡는데 쓰이는 ‘가짜 엄지’ 존재했다고 밝혔다', '화석은 중국 남부 윈난성 자오퉁시 슈이 탕바지역 발굴됐다', '약 만년 전 살았던 고대 판다일루락토스이다', '눈여겨볼은 손목 부위 발견된 돌출뼈다', '연구팀은 뼈 자이언트 판다가 진번째 손가락 일명 ‘가짜 엄지’라고 말했다', '판다가짜 엄지', '뉴시스판다가짜 엄지는 대나무보다 쉽게 잡수 있도록 하는 데 쓰인다', '판다초식 동물 진화하는데 중추적인 역할했을 전문가들은 보고', '그동안 같은 진화적 적응은 약 만년 전 인 비교적 최근 이뤄진 여겨져 왔는데', '연구 무려 만년 거슬러 올라간다는 증명해낸 셈이다', '화석 발견된 가짜 엄지는 현대판다보다 더 긴 길이 직선 모양하고 있었다', '연구팀은 “가짜 엄지는 대나무 잡고 뜯어먹을는 먹이 찾아 걸어갈 몸무게 지탱하는 용도도 쓰이는데', '과정 긴 뼈 짧은 갈고리형 진화하게 된”이라고 분석했다', '왕 박사는 “대나무 먹기 좋게 쪼개기 위해 줄기 단단히 붙잡는 은 많은 양대나무 먹는데 가장 중요한 적응”라며 “육식성 조상 진화해대나무만 먹는 종 바뀐 판다는 많은 장애 넘어야 했을 이고 가짜 엄지는 그 중 가장 놀라운 진화”라고 설명했다', '']\n"
     ]
    }
   ],
   "source": [
    "kospacing_sent_list = []\n",
    "list1 = kospacing_sent.split('.')\n",
    "for i in list1:\n",
    "    i_list1 = i.split(',')\n",
    "    for i_2 in i_list1:\n",
    "        kospacing_sent_list.append(i_2.strip())\n",
    "print(kospacing_sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_from_kiwi_analyzed(comment):\n",
    "    temp_sentence = kiwi.analyze(comment)\n",
    "    noun_list = [token.form for token in temp_sentence[0][0] if re.match('N', token.tag)]\n",
    "    return noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_noun = []\n",
    "for content in kospacing_sent_list:\n",
    "    for noun in extract_noun_from_kiwi_analyzed(content):\n",
    "        if len(noun) < 2:\n",
    "            continue\n",
    "        else:\n",
    "            content_noun.append(noun)\n",
    "content_noun = list(set(content_noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['판다는 언제부터 대나무만 먹었을까? 600만년 전 화석 봤더니…']\n"
     ]
    }
   ],
   "source": [
    "kospacing_title_list = []\n",
    "list2 = title.split('.')\n",
    "for i in list2:\n",
    "    i_list1 = i.split(',')\n",
    "    for i_2 in i_list1:\n",
    "        kospacing_title_list.append(i_2.strip())\n",
    "print(kospacing_title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_noun = []\n",
    "for title in kospacing_title_list:\n",
    "    for noun in extract_noun_from_kiwi_analyzed(title):\n",
    "        if len(noun) < 2:\n",
    "            continue\n",
    "        else:\n",
    "            title_noun.append(noun)\n",
    "title_noun = list(set(content_noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 66\n",
      "['가능', '가짜', '갈고리', '결과', '고대', '과정', '그동안', '나무', '남부', '뉴시스', '대나무', '독특', '돌출', '동물', '락토스', '로스앤젤레스', '만년', '먹이', '모양', '몸무게', '몸집', '미국', '박물관', '박사', '발견', '발굴', '베이', '부위', '분석', '설명', '손가락', '손목', '슈이', '식성', '엄지', '역할', '연구', '왕샤오밍', '외신', '용도', '윈난성', '육식성', '자연사', '자오퉁시', '자이언트', '장애', '적응', '전문가', '조상', '존재', '주식', '줄기', '중국', '중추', '증명', '지역', '지탱', '직선', '진화', '초식', '최소', '탕바', '픽사', '현대판', '현지', '화석']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(content_noun+title_noun))\n",
    "vocab.sort()\n",
    "print('단어장의 크기 :', len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "N = len(kospacing_sent_list)\n",
    "title_N = len(kospacing_title_list)\n",
    "print(N)\n",
    "print(title_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "# 각 문서에 대해서 아래 연산을 반복\n",
    "for i in range(N):\n",
    "  result.append([])\n",
    "  d = kospacing_sent_list[i]\n",
    "  for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result[-1].append(tf(t, d))\n",
    "        \n",
    "content_tf_ = pd.DataFrame(result, columns = vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>가능</th>\n",
       "      <th>가짜</th>\n",
       "      <th>갈고리</th>\n",
       "      <th>결과</th>\n",
       "      <th>고대</th>\n",
       "      <th>과정</th>\n",
       "      <th>그동안</th>\n",
       "      <th>나무</th>\n",
       "      <th>남부</th>\n",
       "      <th>뉴시스</th>\n",
       "      <th>...</th>\n",
       "      <th>지탱</th>\n",
       "      <th>직선</th>\n",
       "      <th>진화</th>\n",
       "      <th>초식</th>\n",
       "      <th>최소</th>\n",
       "      <th>탕바</th>\n",
       "      <th>픽사</th>\n",
       "      <th>현대판</th>\n",
       "      <th>현지</th>\n",
       "      <th>화석</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    가능  가짜  갈고리  결과  고대  과정  그동안  나무  남부  뉴시스  ...  지탱  직선  진화  초식  최소  탕바  \\\n",
       "0    0   0    0   0   0   0    0   0   0    0  ...   0   0   0   0   0   0   \n",
       "1    0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "2    1   0    0   1   0   0    0   0   0    0  ...   0   0   0   0   1   0   \n",
       "3    0   0    0   1   0   0    0   0   0    0  ...   0   0   0   0   0   0   \n",
       "4    0   1    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "5    0   0    0   0   0   0    0   0   1    0  ...   0   0   0   0   0   1   \n",
       "6    0   0    0   0   1   0    0   0   0    0  ...   0   0   0   0   0   0   \n",
       "7    0   0    0   0   0   0    0   0   0    0  ...   0   0   0   0   0   0   \n",
       "8    0   1    0   0   0   0    0   0   0    0  ...   0   0   0   0   0   0   \n",
       "9    0   1    0   0   0   0    0   0   0    0  ...   0   0   0   0   0   0   \n",
       "10   0   1    0   0   0   0    0   1   0    1  ...   0   0   0   0   0   0   \n",
       "11   0   0    0   0   0   0    0   0   0    0  ...   0   0   1   1   0   0   \n",
       "12   0   0    0   0   0   0    1   0   0    0  ...   0   0   1   0   0   0   \n",
       "13   0   0    0   0   0   0    0   0   0    0  ...   0   0   0   0   0   0   \n",
       "14   0   1    0   0   0   0    0   0   0    0  ...   0   1   0   0   0   0   \n",
       "15   0   1    0   0   0   0    0   1   0    0  ...   1   0   0   0   0   0   \n",
       "16   0   0    1   0   0   1    0   0   0    0  ...   0   0   1   0   0   0   \n",
       "17   0   1    0   0   0   0    0   3   0    0  ...   0   0   2   0   0   0   \n",
       "18   0   0    0   0   0   0    0   0   0    0  ...   0   0   0   0   0   0   \n",
       "\n",
       "    픽사  현대판  현지  화석  \n",
       "0    0    0   0   0  \n",
       "1    1    0   0   0  \n",
       "2    0    0   0   0  \n",
       "3    0    0   1   0  \n",
       "4    0    0   0   0  \n",
       "5    0    0   0   1  \n",
       "6    0    0   0   0  \n",
       "7    0    0   0   0  \n",
       "8    0    0   0   0  \n",
       "9    0    0   0   0  \n",
       "10   0    0   0   0  \n",
       "11   0    0   0   0  \n",
       "12   0    0   0   0  \n",
       "13   0    0   0   0  \n",
       "14   0    1   0   1  \n",
       "15   0    0   0   0  \n",
       "16   0    0   0   0  \n",
       "17   0    0   0   0  \n",
       "18   0    0   0   0  \n",
       "\n",
       "[19 rows x 66 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_tf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>가능</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>가짜</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>갈고리</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>결과</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>고대</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>탕바</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>픽사</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>현대판</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>현지</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>화석</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          IDF\n",
       "가능   1.386294\n",
       "가짜   1.386294\n",
       "갈고리  1.386294\n",
       "결과   1.386294\n",
       "고대   1.386294\n",
       "..        ...\n",
       "탕바   1.386294\n",
       "픽사   1.386294\n",
       "현대판  1.386294\n",
       "현지   1.386294\n",
       "화석   1.386294\n",
       "\n",
       "[66 rows x 1 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result.append(idf(t))\n",
    "\n",
    "content_idf_ = pd.DataFrame(result, index=vocab, columns=[\"IDF\"])\n",
    "content_idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>가능</th>\n",
       "      <th>가짜</th>\n",
       "      <th>갈고리</th>\n",
       "      <th>결과</th>\n",
       "      <th>고대</th>\n",
       "      <th>과정</th>\n",
       "      <th>그동안</th>\n",
       "      <th>나무</th>\n",
       "      <th>남부</th>\n",
       "      <th>뉴시스</th>\n",
       "      <th>...</th>\n",
       "      <th>지탱</th>\n",
       "      <th>직선</th>\n",
       "      <th>진화</th>\n",
       "      <th>초식</th>\n",
       "      <th>최소</th>\n",
       "      <th>탕바</th>\n",
       "      <th>픽사</th>\n",
       "      <th>현대판</th>\n",
       "      <th>현지</th>\n",
       "      <th>화석</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          가능        가짜       갈고리        결과        고대        과정       그동안  \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   1.386294  0.000000  0.000000  1.386294  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  1.386294  0.000000  0.000000  0.000000   \n",
       "4   0.000000  1.386294  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  0.000000  1.386294  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  1.386294  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  1.386294  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  1.386294  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  1.386294   \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  1.386294  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15  0.000000  1.386294  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "16  0.000000  0.000000  1.386294  0.000000  0.000000  1.386294  0.000000   \n",
       "17  0.000000  1.386294  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          나무        남부       뉴시스  ...        지탱        직선        진화        초식  \\\n",
       "0   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1   1.386294  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4   1.386294  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  1.386294  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "10  1.386294  0.000000  1.386294  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  ...  0.000000  0.000000  1.386294  1.386294   \n",
       "12  0.000000  0.000000  0.000000  ...  0.000000  0.000000  1.386294  0.000000   \n",
       "13  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  ...  0.000000  1.386294  0.000000  0.000000   \n",
       "15  1.386294  0.000000  0.000000  ...  1.386294  0.000000  0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000  ...  0.000000  0.000000  1.386294  0.000000   \n",
       "17  4.158883  0.000000  0.000000  ...  0.000000  0.000000  2.772589  0.000000   \n",
       "18  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          최소        탕바        픽사       현대판        현지        화석  \n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000  1.386294  0.000000  0.000000  0.000000  \n",
       "2   1.386294  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3   0.000000  0.000000  0.000000  0.000000  1.386294  0.000000  \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5   0.000000  1.386294  0.000000  0.000000  0.000000  1.386294  \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "14  0.000000  0.000000  0.000000  1.386294  0.000000  1.386294  \n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "16  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "18  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[19 rows x 66 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(N):\n",
    "  result.append([])\n",
    "  d = kospacing_sent_list[i]\n",
    "  for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result[-1].append(tfidf(t,d))\n",
    "\n",
    "content_tfidf_ = pd.DataFrame(result, columns = vocab)\n",
    "content_tfidf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "\n",
    "# 각 문서에 대해서 아래 연산을 반복\n",
    "for i in range(N):\n",
    "  result.append([])\n",
    "  d = kospacing_title_list[0]\n",
    "  for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result[-1].append(tf(t, d))\n",
    "        \n",
    "title_tf_ = pd.DataFrame(result, columns = vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>가능</th>\n",
       "      <th>가짜</th>\n",
       "      <th>갈고리</th>\n",
       "      <th>결과</th>\n",
       "      <th>고대</th>\n",
       "      <th>과정</th>\n",
       "      <th>그동안</th>\n",
       "      <th>나무</th>\n",
       "      <th>남부</th>\n",
       "      <th>뉴시스</th>\n",
       "      <th>...</th>\n",
       "      <th>지탱</th>\n",
       "      <th>직선</th>\n",
       "      <th>진화</th>\n",
       "      <th>초식</th>\n",
       "      <th>최소</th>\n",
       "      <th>탕바</th>\n",
       "      <th>픽사</th>\n",
       "      <th>현대판</th>\n",
       "      <th>현지</th>\n",
       "      <th>화석</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    가능  가짜  갈고리  결과  고대  과정  그동안  나무  남부  뉴시스  ...  지탱  직선  진화  초식  최소  탕바  \\\n",
       "0    0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "1    0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "2    0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "3    0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "4    0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "5    0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "6    0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "7    0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "8    0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "9    0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "10   0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "11   0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "12   0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "13   0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "14   0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "15   0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "16   0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "17   0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "18   0   0    0   0   0   0    0   1   0    0  ...   0   0   0   0   0   0   \n",
       "\n",
       "    픽사  현대판  현지  화석  \n",
       "0    0    0   0   1  \n",
       "1    0    0   0   1  \n",
       "2    0    0   0   1  \n",
       "3    0    0   0   1  \n",
       "4    0    0   0   1  \n",
       "5    0    0   0   1  \n",
       "6    0    0   0   1  \n",
       "7    0    0   0   1  \n",
       "8    0    0   0   1  \n",
       "9    0    0   0   1  \n",
       "10   0    0   0   1  \n",
       "11   0    0   0   1  \n",
       "12   0    0   0   1  \n",
       "13   0    0   0   1  \n",
       "14   0    0   0   1  \n",
       "15   0    0   0   1  \n",
       "16   0    0   0   1  \n",
       "17   0    0   0   1  \n",
       "18   0    0   0   1  \n",
       "\n",
       "[19 rows x 66 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tf_.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>가능</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>가짜</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>갈고리</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>결과</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>고대</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>탕바</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>픽사</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>현대판</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>현지</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>화석</th>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          IDF\n",
       "가능   1.386294\n",
       "가짜   1.386294\n",
       "갈고리  1.386294\n",
       "결과   1.386294\n",
       "고대   1.386294\n",
       "..        ...\n",
       "탕바   1.386294\n",
       "픽사   1.386294\n",
       "현대판  1.386294\n",
       "현지   1.386294\n",
       "화석   1.386294\n",
       "\n",
       "[66 rows x 1 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result.append(idf(t))\n",
    "\n",
    "title_idf_ = pd.DataFrame(result, index=vocab, columns=[\"IDF\"])\n",
    "title_idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TfidfVectorizer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Documents\\github\\bigdata_thunder\\bigdata2\\practice_bigdata_project.ipynb 셀 81\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/github/bigdata_thunder/bigdata2/practice_bigdata_project.ipynb#Y140sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(vocab)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/github/bigdata_thunder/bigdata2/practice_bigdata_project.ipynb#Y140sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     t \u001b[39m=\u001b[39m vocab[j]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/github/bigdata_thunder/bigdata2/practice_bigdata_project.ipynb#Y140sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     result[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mappend(tfidf(t, d))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/github/bigdata_thunder/bigdata2/practice_bigdata_project.ipynb#Y140sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m title_tfidf_ \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(result, columns \u001b[39m=\u001b[39m vocab)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TfidfVectorizer' object is not callable"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "\n",
    "# 각 문서에 대해서 아래 연산을 반복\n",
    "for i in range(N):\n",
    "  result.append([])\n",
    "  d = kospacing_title_list[0]\n",
    "  for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result[-1].append(tfidf(t, d))\n",
    "        \n",
    "title_tfidf_ = pd.DataFrame(result, columns = vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>가능</th>\n",
       "      <th>가짜</th>\n",
       "      <th>갈고리</th>\n",
       "      <th>결과</th>\n",
       "      <th>고대</th>\n",
       "      <th>과정</th>\n",
       "      <th>그동안</th>\n",
       "      <th>나무</th>\n",
       "      <th>남부</th>\n",
       "      <th>뉴시스</th>\n",
       "      <th>...</th>\n",
       "      <th>지탱</th>\n",
       "      <th>직선</th>\n",
       "      <th>진화</th>\n",
       "      <th>초식</th>\n",
       "      <th>최소</th>\n",
       "      <th>탕바</th>\n",
       "      <th>픽사</th>\n",
       "      <th>현대판</th>\n",
       "      <th>현지</th>\n",
       "      <th>화석</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     가능   가짜  갈고리   결과   고대   과정  그동안        나무   남부  뉴시스  ...   지탱   직선   진화  \\\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "13  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "14  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "15  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "16  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "17  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "18  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "     초식   최소   탕바   픽사  현대판   현지        화석  \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "11  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "13  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "14  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "15  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "16  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "17  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "18  0.0  0.0  0.0  0.0  0.0  0.0  1.386294  \n",
       "\n",
       "[19 rows x 66 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tfidf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosine_similarity import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 66)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(title_tf_.values, content_tf_.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(content_tf_.values, title_tf_.values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
